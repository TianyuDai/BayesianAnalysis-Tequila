{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb0d1982",
   "metadata": {},
   "source": [
    "# Closure test of Bayesian analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "503f6dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare\n",
    "import subprocess\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import os, pickle, math, time\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# sns.set(\"notebook\")\n",
    "sns.color_palette('Set2')\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor as gpr\n",
    "from sklearn.gaussian_process import kernels as krnl\n",
    "\n",
    "import scipy.stats as st\n",
    "from scipy import optimize\n",
    "from scipy.linalg import lapack\n",
    "\n",
    "from pyDOE import lhs\n",
    "import emcee\n",
    "import h5py\n",
    "\n",
    "FW = 600\n",
    "\n",
    "path = '/mnt/d/research/Bayesian/BayesianAnalysis-Tequila'\n",
    "\n",
    "def save_fig(fig_id):\n",
    "    plt.savefig(path+fig_id, format='png', dpi=300)\n",
    "    \n",
    "def hist_1d_2d(X, Y, nameX, nameY):\n",
    "    left, width = 0.1, 0.75\n",
    "    bottom, height = 0.1, 0.75\n",
    "    spacing = 0.005\n",
    "    rect_scatter = [left, bottom, width, height]\n",
    "    rect_histx = [left, bottom + height + spacing, width, 0.15]\n",
    "    rect_histy = [left + width + spacing, bottom, 0.15, height]\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    ax = fig.add_axes(rect_scatter)\n",
    "    ax1 = fig.add_axes(rect_histx, sharex=ax)\n",
    "    ax2 = fig.add_axes(rect_histy, sharey=ax)\n",
    "    ax1.tick_params(axis=\"x\", labelbottom=False)\n",
    "    ax2.tick_params(axis=\"y\", labelleft=False)\n",
    "\n",
    "    ax.scatter(X, Y)\n",
    "    ax1.hist(X, density=True)\n",
    "    ax2.hist(Y, orientation='horizontal', density=True)\n",
    "    ax.set_xlabel(nameX)\n",
    "    ax.set_ylabel(nameY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bca9edd",
   "metadata": {},
   "source": [
    "## Gaussian emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11a102be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian emulator\n",
    "\n",
    "simulation = np.loadtxt(os.path.join(path, 'data', 'running_coupling', 'output_4obs'))\n",
    "simulation_err = np.loadtxt(os.path.join(path, 'data', 'running_coupling', 'output_err_4obs'))\n",
    "\n",
    "use_NL = True\n",
    "Y_model = np.sqrt(simulation) if use_NL else simulation\n",
    "\n",
    "SS  =  StandardScaler(copy=True)\n",
    "Npc = 4\n",
    "pca = PCA(copy=True, whiten=True, svd_solver='full')\n",
    "# Keep only the first `npc` principal components\n",
    "pc_tf_data = pca.fit_transform(SS.fit_transform(Y_model)) [:,:Npc]\n",
    "\n",
    "# The transformation matrix from PC to Physical space\n",
    "inverse_tf_matrix = pca.components_ * np.sqrt(pca.explained_variance_[:, np.newaxis]) * SS.scale_ \n",
    "inverse_tf_matrix = inverse_tf_matrix[:Npc,:]\n",
    "\n",
    "\n",
    "np.savetxt(path+'/data/inverse_tf_matrix', inverse_tf_matrix)\n",
    "np.savetxt(path+'/data/PCA_transformed_data', pc_tf_data)\n",
    "\n",
    "design = np.loadtxt(path+'/data/running_coupling/new_param/lhd_sampling_5d.txt')\n",
    "# design = design[:32]\n",
    "design_max = np.array([2., 2., 0.6, 3.5, 0.4])\n",
    "design_min = np.array([-0.8, -0.8, 0.16, 1.15, 0.1])\n",
    "design_ptp = design_max - design_min\n",
    "# design_ptp = np.array([1.9, 1.9, 1.9, 0.34, 2., 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a438a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9kAAAGBCAYAAABy9nJZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNN0lEQVR4nO3deVyU9f7//+ewizi4simukGaJfqX0g7a4kGh93PJ0TCuVyo4GpVBZdlTUFq2Oa5lkZepJU/OjtmuGiqdyVzQ75RaGpwC3oyimKFy/P/o550wgMTZwDTOP++02t7iu632953lxVW9e876uayyGYRgCAAAAAAB/mJfZAQAAAAAAcBcU2QAAAAAAOAlFNgAAAAAATkKRDQAAAACAk1BkAwAAAADgJBTZAAAAAAA4CUU2AAAAAABOQpENAAAAAICTUGQDAAAAAOAkFNkAAAAAADiJqUX23LlzFRMTI6vVKqvVqri4OH322We27V26dJHFYrF7jRgxwsTEAAAAAABcncUwDMOsN//oo4/k7e2t6OhoGYahhQsX6pVXXtHu3bt1ww03qEuXLrruuus0efJk2z6BgYGyWq1l9ldSUqKff/5ZtWrVksViqarDAADAIYZh6OzZs4qIiJCXl2dfVMbYDQCoDhwZu32qKFOZevfubbf8wgsvaO7cudqyZYtuuOEGSb8W1WFhYRXq7+eff1ZkZKTTcwIAUBmOHj2qRo0amR3DVIzdAIDqpCJjt6lF9n8rLi7W+++/r8LCQsXFxdnWL168WO+++67CwsLUu3dvjR8/XoGBgWX2UatWLUnSP//5T9vPkuTv7y9/f//KPQAAACqooKBAkZGRdmOVp7ryOzh69OhVr1QDAMBsjozdphfZ33zzjeLi4nThwgUFBQVp1apVat26tSRp8ODBatKkiSIiIrR37149/fTT2r9/v1auXFlmX1cuM7uy/xVpaWmaOHFipR4HAACO4vLo//wOrjyfBQAAV1aRsdv0Irtly5bKysrSmTNntGLFCg0dOlSZmZlq3bq1HnnkEVu7Nm3aKDw8XN27d9fhw4fVokWLq/b520/DmcUGAAAAAFQF04tsPz8/RUVFSZJiY2O1fft2zZo1S2+88Uapth07dpQkHTp0qNwim0/DAQAAAABmcLlHmpaUlOjixYtlbsvKypIkhYeHV2EiAAAAAAAqxtSZ7LFjx6pXr15q3Lixzp49qyVLlmjjxo1au3atDh8+rCVLlujOO+9UvXr1tHfvXqWkpOi2225TTEyMmbEBAAAAACiTqUX2sWPHNGTIEOXm5io4OFgxMTFau3at7rjjDh09elRffPGFZs6cqcLCQkVGRmrAgAEaN26cmZEBAAAAALgqU4vst99++6rbIiMjlZmZWYVpAAAAAAD4Y1zunmwAAAAAAKorimwAAFCmTZs2qXfv3oqIiJDFYtHq1at/d5+NGzeqffv28vf3V1RUlBYsWFDpOQEAcCUU2QAAoEyFhYVq27at5syZU6H22dnZuuuuu9S1a1dlZWVp9OjRevjhh7V27dpKTgoAgOsw/XuyAQCAa+rVq5d69epV4fbp6elq1qyZpk2bJkm6/vrr9eWXX2rGjBlKSEiorJgAALgUZrIBAIBTbN68WfHx8XbrEhIStHnzZpMSAQBQ9ZjJBgAATpGXl6fQ0FC7daGhoSooKNAvv/yiGjVqXHXfgoICu2V/f3/5+/tXSk4AACoTRfbv+HDb+atu69MhsAqTAADgviIjI+2W09LSNHHiRHPCAB6mvL93pV//5q1Im4r2VdXtXDlbRdu5crYr7Vw5W1WjyAYAAE4RFham/Px8u3X5+fmyWq3lzmJL0tGjR2W1Wm3LzGLDUa7+B74rF1AAnIsiGwAAOEVcXJw+/fRTu3Xr1q1TXFzc7+5rtVrtimxULVcsPCvajkIRgKuhyAYAAGU6d+6cDh06ZFvOzs5WVlaW6tatq8aNG2vs2LH66aeftGjRIknSiBEj9Nprr2nMmDF68MEHtX79ei1fvlyffPKJWYfg1pjNBADXRJENAADKtGPHDnXt2tW2nJqaKkkaOnSoFixYoNzcXOXk5Ni2N2vWTJ988olSUlI0a9YsNWrUSG+99RZf3/X/oygGAM9AkQ0AAMrUpUsXGYZx1e0LFiwoc5/du3dXYirXxOXMAIAr+J5sAAAAAACchCIbAAAAAAAnocgGAAAAAMBJKLIBAAAAAHASimwAAAAAAJyEIhsAAAAAACehyAYAAAAAwEkosgEAAAAAcBIfswMAAAC4qg+3nS93e58OgVWUBABQXTCTDQAAAACAk1BkAwAAAADgJBTZAAAAAAA4CUU2AAAAAABOQpENAAAAAICTUGQDAAAAAOAkFNkAAAAAADgJRTYAAAAAAE5CkQ0AAAAAgJNQZAMAAAAA4CQU2QAAAAAAOAlFNgAAAAAATkKRDQAAAACAk1BkAwAAAADgJKYW2XPnzlVMTIysVqusVqvi4uL02Wef2bZfuHBBSUlJqlevnoKCgjRgwADl5+ebmBgAAAAAgKsztchu1KiRpk6dqp07d2rHjh3q1q2b+vbtq2+//VaSlJKSoo8++kjvv/++MjMz9fPPP+vuu+82MzIAAAAAAFflY+ab9+7d2275hRde0Ny5c7VlyxY1atRIb7/9tpYsWaJu3bpJkt555x1df/312rJli/7nf/7HjMgAAAAAAFyVy9yTXVxcrKVLl6qwsFBxcXHauXOnLl26pPj4eFubVq1aqXHjxtq8eXO5fRUUFNi9Ll68WNnxAQAAAAAwv8j+5ptvFBQUJH9/f40YMUKrVq1S69atlZeXJz8/P9WuXduufWhoqPLy8srtMzIyUsHBwbbXlClTKvEIAAAAAAD4lamXi0tSy5YtlZWVpTNnzmjFihUaOnSoMjMz/1CfR48eldVqtS37+/v/0ZgAAAAAAPwu04tsPz8/RUVFSZJiY2O1fft2zZo1SwMHDlRRUZFOnz5tN5udn5+vsLCwcvu88rRyAACAsny47Xy52/t0CKyiJAAAd2P65eK/VVJSoosXLyo2Nla+vr7KyMiwbdu/f79ycnIUFxdnYkIAAAAAAMpm6kz22LFj1atXLzVu3Fhnz57VkiVLtHHjRq1du1bBwcF66KGHlJqaqrp168pqteqxxx5TXFwcTxYHAAAAALgkU4vsY8eOaciQIcrNzVVwcLBiYmK0du1a3XHHHZKkGTNmyMvLSwMGDNDFixeVkJCg119/3czIAAAAAABclalF9ttvv13u9oCAAM2ZM0dz5sypokQAAAAAAFw7l7snGwAAAACA6ooiGwAAAAAAJ6HIBgAAAADASSiyAQAAAABwEopsAAAAAACchCIbAAAAAAAnocgGAAAAAMBJKLIBAAAAAHASimwAAAAAAJyEIhsAAAAAACehyAYAAAAAwEkosgEAAAAAcBKKbAAAAAAAnIQiGwAAAAAAJ6HIBgAAAADASSiyAQAAAABwEopsAAAAAACchCIbAACUa86cOWratKkCAgLUsWNHbdu2rdz2M2fOVMuWLVWjRg1FRkYqJSVFFy5cqKK0AACYiyIbAABc1bJly5Samqq0tDTt2rVLbdu2VUJCgo4dO1Zm+yVLluiZZ55RWlqavvvuO7399ttatmyZnn322SpODgCAOSiyAQDAVU2fPl3Dhw9XYmKiWrdurfT0dAUGBmr+/Plltv/666/VuXNnDR48WE2bNlWPHj00aNCg3539BgDAXVBkAwDgZk6fPq233npLY8eO1alTpyRJu3bt0k8//eRQP0VFRdq5c6fi4+Nt67y8vBQfH6/NmzeXuU+nTp20c+dOW1H9ww8/6NNPP9Wdd95Z7nsVFBTYvS5evOhQVgAAXIWP2QEAAIDz7N27V/Hx8QoODtaRI0c0fPhw1a1bVytXrlROTo4WLVpU4b5OnDih4uJihYaG2q0PDQ3V999/X+Y+gwcP1okTJ3TLLbfIMAxdvnxZI0aM+N3LxSMjI+2W09LSNHHixApnBQDAVTCTDQCAG0lNTdWwYcN08OBBBQQE2Nbfeeed2rRpU6W//8aNG/Xiiy/q9ddf165du7Ry5Up98skneu6558rd7+jRozpz5oztNXbs2ErPCgBAZWAmGwAAN7J9+3a98cYbpdY3bNhQeXl5DvVVv359eXt7Kz8/3259fn6+wsLCytxn/PjxeuCBB/Twww9Lktq0aaPCwkI98sgj+utf/yovr7I/37darbJarQ7lAwDAFTGTDQCAG/H391dBQUGp9QcOHFCDBg0c6svPz0+xsbHKyMiwrSspKVFGRobi4uLK3Of8+fOlCmlvb29JkmEYDr0/AADVEUU2AABupE+fPpo8ebIuXbokSbJYLMrJydHTTz+tAQMGONxfamqq3nzzTS1cuFDfffedRo4cqcLCQiUmJkqShgwZYndpd+/evTV37lwtXbpU2dnZWrduncaPH6/evXvbim0AANwZl4sDAOBGpk2bpj/96U8KCQnRL7/8ottvv115eXmKi4vTCy+84HB/AwcO1PHjxzVhwgTl5eWpXbt2WrNmje1haDk5OXYz1+PGjZPFYtG4ceP0008/qUGDBurdu/c1vTcAANURRTYAAG4kODhY69at01dffaU9e/bo3Llzat++vd3XcDkqOTlZycnJZW7buHGj3bKPj4/S0tKUlpZ2ze8HAEB1RpENAIAb6ty5szp37mx2DAAAPA73ZAMA4EYef/xxzZ49u9T61157TaNHj676QAAAeBiKbAAA3Mj//d//lTmD3alTJ61YscKERAAAeBaKbAAA3MjJkycVHBxcar3VatWJEydMSAQAgGehyAYAwI1ERUVpzZo1pdZ/9tlnat68uQmJAADwLDz4DAAAN5Kamqrk5GQdP35c3bp1kyRlZGRo2rRpmjlzprnhAADwAKbOZE+ZMkU333yzatWqpZCQEPXr10/79++3a9OlSxdZLBa714gRI0xKDACAa3vwwQc1bdo0vf322+ratau6du2qd999V3PnztXw4cPNjgcAgNszdSY7MzNTSUlJuvnmm3X58mU9++yz6tGjh/75z3+qZs2atnbDhw/X5MmTbcuBgYFmxAUAoFoYOXKkRo4cqePHj6tGjRoKCgoyOxIAAB7D1CL7t/eMLViwQCEhIdq5c6duu+022/rAwECFhYVVdTwAAKq1Bg0amB0BAACP41IPPjtz5owkqW7dunbrFy9erPr16+vGG2/U2LFjdf78eTPiAQDg8vLz8/XAAw8oIiJCPj4+8vb2tnsBAIDK5TIPPispKdHo0aPVuXNn3Xjjjbb1gwcPVpMmTRQREaG9e/fq6aef1v79+7Vy5cqr9lVQUGC37O/vL39//0rLDgCAqxg2bJhycnI0fvx4hYeHy2KxmB0JAACP4jJFdlJSkvbt26cvv/zSbv0jjzxi+7lNmzYKDw9X9+7ddfjwYbVo0aLMviIjI+2W09LSNHHiRKdnBgDA1Xz55Zf6xz/+oXbt2pkdBQAAj+QSRXZycrI+/vhjbdq0SY0aNSq3bceOHSVJhw4dumqRffToUVmtVtsys9gAAE8RGRkpwzDMjgEAgMcy9Z5swzCUnJysVatWaf369WrWrNnv7pOVlSVJCg8Pv2obq9Vq96LIBgB4ipkzZ+qZZ57RkSNHzI4CAIBHMnUmOykpSUuWLNEHH3ygWrVqKS8vT5IUHBysGjVq6PDhw1qyZInuvPNO1atXT3v37lVKSopuu+02xcTEmBkdAACXNHDgQJ0/f14tWrRQYGCgfH197bafOnXKpGQAAHgGU4vsuXPnSpK6dOlit/6dd97RsGHD5Ofnpy+++EIzZ85UYWGhIiMjNWDAAI0bN86EtAAAuL6ZM2eaHQEAAI9mapH9e/eMRUZGKjMzs4rSAABQ/Q0dOtTsCAAAeDSXePAZAABwvgsXLqioqMhu3X8/GBQAADifqQ8+AwAAzlVYWKjk5GSFhISoZs2aqlOnjt0LAABULopsAADcyJgxY7R+/XrNnTtX/v7+euuttzRp0iRFRERo0aJFZscDAMDtcbk4AABu5KOPPtKiRYvUpUsXJSYm6tZbb1VUVJSaNGmixYsX67777jM7IgAAbo2ZbAAA3MipU6fUvHlzSb/ef33lK7tuueUWbdq0ycxoAAB4BIpsAADcSPPmzZWdnS1JatWqlZYvXy7p1xnu2rVrm5gMAADPQJENAIAbSUxM1J49eyRJzzzzjObMmaOAgAClpKToqaeeMjkdAADuj3uyAQBwIykpKbaf4+Pj9f3332vnzp2KiopSTEyMickAAPAMFNkAALixJk2aqEmTJmbHqDIfbjtf7vY+HQKrKAkAwFNRZAMAUM3Nnj1bjzzyiAICAjR79uxy2z7++ONVlAoAAM9EkQ0AQDU3Y8YM3XfffQoICNCMGTOu2s5isVBkAwBQySiyAQCo5q48Tfy3PwMAgKrH08UBAHATly5dUosWLfTdd9+ZHQUAAI9FkQ0AgJvw9fXVhQsXzI4BAIBHo8gGAMCNJCUl6aWXXtLly5fNjgIAgEfinmwAANzI9u3blZGRoc8//1xt2rRRzZo17bavXLnSpGQAAHgGimwAANxI7dq1NWDAALNjAADgsSiyAQBwI++8847ZEQAA8Gjckw0AAAAAgJMwkw0AgJtZsWKFli9frpycHBUVFdlt27Vrl0mpAADwDMxkAwDgRmbPnq3ExESFhoZq9+7d6tChg+rVq6cffvhBvXr1MjseAABujyIbAAA38vrrr2vevHl69dVX5efnpzFjxmjdunV6/PHHdebMGbPjAQDg9iiyAQBwIzk5OerUqZMkqUaNGjp79qwk6YEHHtB7771nZjQAADwCRTYAAG4kLCxMp06dkiQ1btxYW7ZskSRlZ2fLMAwzowEA4BEosgEAcCPdunXThx9+KElKTExUSkqK7rjjDg0cOFD9+/c3OR0AAO6Pp4sDAOBG5s2bp5KSEklSUlKS6tWrp6+//lp9+vTRX/7yF5PTAQDg/iiyAQBwI15eXvLy+s+Favfee6/uvfdeExMBAOBZuFwcAAA3EhUVpYkTJ+rAgQNmRwEAwCNRZAMA4EaSkpL0ySef6Prrr9fNN9+sWbNmKS8vz+xYAAB4DIpsAADcSEpKirZv367vvvtOd955p+bMmaPIyEj16NFDixYtMjseAABujyIbAAA3dN1112nSpEk6cOCA/vGPf+j48eNKTEw0OxYAAG6PB58BAOCmtm3bpiVLlmjZsmUqKCjQPffcY3YkAADcHkU2AABu5MCBA1q8eLHee+89ZWdnq1u3bnrppZd09913KygoyOx4AAC4vWsqsi9fvqyNGzfq8OHDGjx4sGrVqqWff/5ZVquVARwAABO1atVKN998s5KSknTvvfcqNDTU7EgAAHgUh+/J/vHHH9WmTRv17dtXSUlJOn78uCTppZde0pNPPun0gAAAoOL279+vrVu3atSoUU4rsOfMmaOmTZsqICBAHTt21LZt28ptf/r0aSUlJSk8PFz+/v667rrr9OmnnzolCwAArs7hInvUqFG66aab9O9//1s1atSwre/fv78yMjIc6mvKlCm6+eabVatWLYWEhKhfv37av3+/XZsLFy4oKSlJ9erVU1BQkAYMGKD8/HxHYwMA4BGio6Od2t+yZcuUmpqqtLQ07dq1S23btlVCQoKOHTtWZvuioiLdcccdOnLkiFasWKH9+/frzTffVMOGDZ2aCwAAV+Vwkf2Pf/xD48aNk5+fn936pk2b6qeffnKor8zMTCUlJWnLli1at26dLl26pB49eqiwsNDWJiUlRR999JHef/99ZWZm6ueff9bdd9/taGwAAHANpk+fruHDhysxMVGtW7dWenq6AgMDNX/+/DLbz58/X6dOndLq1avVuXNnNW3aVLfffrvatm1bxckBADCHw/dkl5SUqLi4uNT6f/3rX6pVq5ZDfa1Zs8ZuecGCBQoJCdHOnTt122236cyZM3r77be1ZMkSdevWTZL0zjvv6Prrr9eWLVv0P//zP47GBwAAFVRUVKSdO3dq7NixtnVeXl6Kj4/X5s2by9znww8/VFxcnJKSkvTBBx+oQYMGGjx4sJ5++ml5e3tf9b0KCgrslv39/eXv7++cAwEAoAo5PJPdo0cPzZw507ZssVh07tw5paWl6c477/xDYc6cOSNJqlu3riRp586dunTpkuLj421tWrVqpcaNG191cAcAAM5x4sQJFRcXl7q3OzQ0VHl5eWXu88MPP2jFihUqLi7Wp59+qvHjx2vatGl6/vnny32vyMhIBQcH215Tpkxx2nEAAFCVHJ7JnjZtmhISEtS6dWtduHBBgwcP1sGDB1W/fn2999571xykpKREo0ePVufOnXXjjTdKkvLy8uTn56fatWvbtS1vcJf4NBwAALOUlJQoJCRE8+bNk7e3t2JjY/XTTz/plVdeUVpa2lX3O3r0qKxWq22ZcRsAUF05XGQ3atRIe/bs0bJly7Rnzx6dO3dODz30kO677z67B6E5KikpSfv27dOXX355zX1cERkZabeclpamiRMn/uF+AQBwRampqRVuO3369Aq3rV+/vry9vUs9cDQ/P19hYWFl7hMeHi5fX1+7S8Ovv/565eXlqaioqNQzXa6wWq12RTYAANXVNX1Pto+Pj+677z7dd999TgmRnJysjz/+WJs2bVKjRo1s68PCwlRUVKTTp0/bzWaXN7hLfBoOAPAsu3fvrlA7i8XiUL9+fn6KjY1VRkaG+vXrJ+nXmeqMjAwlJyeXuU/nzp21ZMkSlZSUyMvr17vSDhw4oPDw8KsW2AAAuBOHi+wpU6YoNDRUDz74oN36+fPn6/jx43r66acr3JdhGHrssce0atUqbdy4Uc2aNbPbHhsbK19fX2VkZGjAgAGSfv3+z5ycHMXFxV21Xz4NBwB4kg0bNlRa36mpqRo6dKhuuukmdejQQTNnzlRhYaESExMlSUOGDFHDhg1t91CPHDlSr732mkaNGqXHHntMBw8e1IsvvqjHH3+80jICAOBKHC6y33jjDS1ZsqTU+htuuEH33nuvQ0V2UlKSlixZog8++EC1atWy3WcdHBysGjVqKDg4WA899JBSU1NVt25dWa1WPfbYY4qLi+PJ4gAAVIGBAwfq+PHjmjBhgvLy8tSuXTutWbPG9jC0nJwc24y19OstW2vXrlVKSopiYmLUsGFDjRo1yqG/DwAAqM4cLrLz8vIUHh5ean2DBg2Um5vrUF9z586VJHXp0sVu/TvvvKNhw4ZJkmbMmCEvLy8NGDBAFy9eVEJCgl5//XVHYwMA4DF27Nih5cuXKycnR0VFRXbbVq5c6XB/ycnJV708fOPGjaXWxcXFacuWLQ6/DwAA7sDhr/CKjIzUV199VWr9V199pYiICIf6MgyjzNeVAluSAgICNGfOHJ06dUqFhYVauXJlufdjAwDgyZYuXapOnTrpu+++06pVq3Tp0iV9++23Wr9+vYKDg82OBwCA23N4Jnv48OEaPXq0Ll26pG7dukmSMjIyNGbMGD3xxBNODwgAACruxRdf1IwZM5SUlKRatWpp1qxZatasmf7yl7+UeSUaAABwLoeL7KeeekonT57Uo48+arsELSAgQE8//bTGjh3r9IAAAKDiDh8+rLvuukvSr08HLywslMViUUpKirp166ZJkyaZnBAAAPfmcJFtsVj00ksvafz48fruu+9Uo0YNRUdH8zVZAAC4gDp16ujs2bOSpIYNG2rfvn1q06aNTp8+rfPnz5ucDgAA93dN35MtSUFBQbr55pudmQUAAPxBt912m9atW6c2bdronnvu0ahRo7R+/XqtW7dO3bt3NzseAABuz+Eiu7CwUFOnTlVGRoaOHTumkpISu+0//PCD08IBAADHvPbaa7pw4YIk6a9//at8fX319ddfa8CAARo3bpzJ6QAAcH8OF9kPP/ywMjMz9cADDyg8PFwWi6UycgEAgGtQt25d289eXl565plnTEwDAIDncbjI/uyzz/TJJ5+oc+fOlZEHAAD8Ad7e3srNzVVISIjd+pMnTyokJETFxcUmJQMAwDM4/D3ZderUsfuUHAAAuA7DMMpcf/HiRfn5+VVxGgAAPI/DM9nPPfecJkyYoIULFyowMLAyMgEAAAfNnj1b0q/fAvLWW28pKCjItq24uFibNm1Sq1atzIoHAIDHcLjInjZtmg4fPqzQ0FA1bdpUvr6+dtt37drltHAAAKBiZsyYIenXmez09HR5e3vbtvn5+alp06ZKT083Kx4AAB7D4SK7X79+lRADAAD8EdnZ2ZKkrl27auXKlapTp47JiQAA8EwOF9lpaWmVkQMAADjBhg0bbD9fuT+bbwIBAKDqOPzgMwAA4NoWLVqkNm3aqEaNGqpRo4ZiYmL097//3exYAAB4BIdnsouLizVjxgwtX75cOTk5Kioqstt+6tQpp4UDAACOmT59usaPH6/k5GTb121++eWXGjFihE6cOKGUlBSTEwIA4N4cnsmeNGmSpk+froEDB+rMmTNKTU3V3XffLS8vL02cOLESIgIAgIp69dVXNXfuXL300kvq06eP+vTpo5dfflmvv/667QnkAACg8jhcZC9evFhvvvmmnnjiCfn4+GjQoEF66623NGHCBG3ZsqUyMgIAgArKzc1Vp06dSq3v1KmTcnNzTUgEAIBncbjIzsvLU5s2bSRJQUFBOnPmjCTpf//3f/XJJ584Nx0AAHBIVFSUli9fXmr9smXLFB0dbUIiAAA8i8P3ZDdq1Ei5ublq3LixWrRooc8//1zt27fX9u3b5e/vXxkZAQBABU2aNEkDBw7Upk2bbPdkf/XVV8rIyCiz+AYAAM7l8Ex2//79lZGRIUl67LHHNH78eEVHR2vIkCF68MEHnR4QAABU3IABA7R161bVr19fq1ev1urVq1W/fn1t27ZN/fv3NzseAABuz+GZ7KlTp9p+HjhwoBo3bqzNmzcrOjpavXv3dmo4AADguNjYWL377rtmxwAAwCM5XGT/VlxcnOLi4pyRBQAA/EHe3t7Kzc1VSEiI3fqTJ08qJCRExcXFJiUDAMAzVKjI/vDDD9WrVy/5+vrqww8/LLdtnz59nBIMAAA4zjCMMtdfvHhRfn5+VZwGAADPU6Eiu1+/fsrLy1NISIj69et31XYWi4VPyAEAMMGV78C2WCx66623FBQUZNtWXFysTZs2qVWrVmbFAwDAY1SoyC4pKSnzZwAA4BpmzJgh6deZ7PT0dHl7e9u2+fn5qWnTpkpPTzcrHgAAHsOhe7IvXbqknj17Kj09ne/aBADAhWRnZ0uSunbtqpUrV6pOnTomJwIAwDM5VGT7+vpq7969lZUFAAD8QRs2bDA7AgAAHs3h78m+//779fbbb1dGFgAAAAAAqjWHv8Lr8uXLmj9/vr744gvFxsaqZs2adtunT5/utHAAAAAAAFQnDhfZ+/btU/v27SVJBw4csNtmsVickwoAAAAAgGrI4SKbe70AAHAtd999txYsWCCr1apFixZp4MCB8vf3NzsWAAAeyeF7sgEAgGv5+OOPVVhYKElKTEzUmTNnTE4EAIDncngmW5J27Nih5cuXKycnR0VFRXbbVq5c6ZRgAACgYlq1aqWxY8eqa9euMgxDy5cvl9VqLbPtkCFDqjgdAACexeEie+nSpRoyZIgSEhL0+eefq0ePHjpw4IDy8/PVv3//ysgIAADKkZ6ertTUVH3yySeyWCwaN25cmc9JsVgsFNkAAFQyh4vsF198UTNmzFBSUpJq1aqlWbNmqVmzZvrLX/6i8PDwysgIAADK0alTJ23ZskWS5OXlpQMHDigkJMTkVAAAeCaH78k+fPiw7rrrLkmSn5+fCgsLZbFYlJKSonnz5jk9IAAAqLjs7Gw1aNDA7BgAAHgsh4vsOnXq6OzZs5Kkhg0bat++fZKk06dP6/z58w71tWnTJvXu3VsRERGyWCxavXq13fZhw4bJYrHYvXr27OloZAAAPEaTJk105swZTZs2TQ8//LAefvhhTZ8+nYehAQBQRSpcZF8ppm+77TatW7dOknTPPfdo1KhRGj58uAYNGqTu3bs79OaFhYVq27at5syZc9U2PXv2VG5uru313nvvOfQeAAB4kh07dqhFixaaMWOGTp06pVOnTmnGjBlq0aKFdu3aZXY8AADcXoXvyY6JidHNN9+sfv366Z577pEk/fWvf5Wvr6++/vprDRgwQOPGjXPozXv16qVevXqV28bf319hYWEO9QsAgKdKSUlRnz599Oabb8rH59dh/vLly3r44Yc1evRobdq0yeSEAAC4twoX2ZmZmXrnnXc0ZcoUvfDCCxowYIAefvhhPfPMM5WZTxs3blRISIjq1Kmjbt266fnnn1e9evXK3aegoMBu2d/fX/7+/pUZEwAAl7Bjxw67AluSfHx8NGbMGN10000mJgMAwDNU+HLxW2+9VfPnz1dubq5effVVHTlyRLfffruuu+46vfTSS8rLy3N6uJ49e2rRokXKyMjQSy+9pMzMTPXq1UvFxcXl7hcZGang4GDba8qUKU7PBgCAK7JarcrJySm1/ujRo6pVq5YJiQAA8CwOf4VXzZo1lZiYqMTERB06dEjvvPOO5syZo/Hjx6tnz5768MMPnRbu3nvvtf3cpk0bxcTEqEWLFtq4cWO5938fPXpUVqvVtswsNgDAUwwcOFAPPfSQ/va3v6lTp06SpK+++kpPPfWUBg0aZHI6AADcn8NF9n+LiorSs88+qyZNmmjs2LH65JNPnJWrTM2bN1f9+vV16NChcotsq9VqV2QDAOAp/va3v8lisWjIkCG6fPmyJMnX11cjR47U1KlTTU4HAID7u+Yie9OmTZo/f77+7//+T15eXvrzn/+shx56yJnZSvnXv/6lkydPKjw8vFLfBwCA6srPz0+zZs3SlClTdPjwYUlSixYtFBgYaHIyAAA8g0NF9s8//6wFCxZowYIFOnTokDp16qTZs2frz3/+s2rWrOnwm587d06HDh2yLWdnZysrK0t169ZV3bp1NWnSJA0YMEBhYWE6fPiwxowZo6ioKCUkJDj8XgAAeJLAwEC1adPG7BgAAHicChfZvXr10hdffKH69etryJAhevDBB9WyZcs/9OY7duxQ165dbcupqamSpKFDh2ru3Lnau3evFi5cqNOnTysiIkI9evTQc889xz3WAAAAAACXVOEi29fXVytWrND//u//ytvb2ylv3qVLFxmGcdXta9eudcr7AAAAAABQFSpcZDvzqeEAAAAAALijCn9PNgAAAAAAKN8f+govAADgeg4ePKgNGzbo2LFjKikpsds2YcIEk1IBAOAZmMkGAMCNvPnmm7r++us1YcIErVixQqtWrbK9Vq9efU19zpkzR02bNlVAQIA6duyobdu2VWi/pUuXymKxqF+/ftf0vgAAVEfMZAMA4Eaef/55vfDCC3r66aed0t+yZcuUmpqq9PR0dezYUTNnzlRCQoL279+vkJCQq+535MgRPfnkk7r11ludkgMAgOqCmWwAANzIv//9b91zzz1O62/69OkaPny4EhMT1bp1a6WnpyswMFDz58+/6j7FxcW67777NGnSJDVv3txpWQAAqA4osgEAcCP33HOPPv/8c6f0VVRUpJ07dyo+Pt62zsvLS/Hx8dq8efNV95s8ebJCQkL00EMPOSUHAADVCZeLAwDgRqKiojR+/Hht2bJFbdq0ka+vr932xx9/vMJ9nThxQsXFxQoNDbVbHxoaqu+//77Mfb788ku9/fbbysrKcih3QUGB3bK/v7/8/f0d6gMAAFdAkQ0AgBuZN2+egoKClJmZqczMTLttFovFoSLbUWfPntUDDzygN998U/Xr13do38jISLvltLQ0TZw40YnpAACoGhTZAAC4kezsbKf1Vb9+fXl7eys/P99ufX5+vsLCwkq1P3z4sI4cOaLevXvb1l35CjEfHx/t379fLVq0KPO9jh49KqvValtmFhsAUF1xTzYAAG7KMAwZhnHN+/v5+Sk2NlYZGRm2dSUlJcrIyFBcXFyp9q1atdI333yjrKws26tPnz7q2rWrsrKySs1W/zer1Wr3osgGAFRXFNkAALiZRYsWqU2bNqpRo4Zq1KihmJgY/f3vf7+mvlJTU/Xmm29q4cKF+u677zRy5EgVFhYqMTFRkjRkyBCNHTtWkhQQEKAbb7zR7lW7dm3VqlVLN954o/z8/Jx2jAAAuCouFwcAwI1Mnz5d48ePV3Jysjp37izp14eRjRgxQidOnFBKSopD/Q0cOFDHjx/XhAkTlJeXp3bt2mnNmjW2h6Hl5OTIy4vP7AEAuIIiGwAAN/Lqq69q7ty5GjJkiG1dnz59dMMNN2jixIkOF9mSlJycrOTk5DK3bdy4sdx9FyxY4PD7AQBQnfHRMwAAbiQ3N1edOnUqtb5Tp07Kzc01IREAAJ6FIhsAADcSFRWl5cuXl1q/bNkyRUdHm5AIAADPwuXiAAC4kUmTJmngwIHatGmT7Z7sr776ShkZGWUW3wAAwLmYyQYAwI0MGDBAW7duVf369bV69WqtXr1a9evX17Zt29S/f3+z4wEA4PaYyQYAwM3Exsbq3XffNTsGAAAeiSIbAIBqrqCgQFar1fZzea60AwAAlYMiGwCAaq5OnTrKzc1VSEiIateuLYvFUqqNYRiyWCwqLi42ISEAAJ6DIhsAgGpu/fr1qlu3riRpw4YNJqcBAMCzUWQDAFDN3X777bafmzVrpsjIyFKz2YZh6OjRo1UdDQAAj8PTxQEAcCPNmjXT8ePHS60/deqUmjVrZkIiAAA8C0U2AABu5Mq917917tw5BQQEmJAIAADPwuXiAAC4gdTUVEmSxWLR+PHjFRgYaNtWXFysrVu3ql27dialAwDAc1BkAwDgBnbv3i3p15nsb775Rn5+frZtfn5+atu2rZ588kmz4gEA4DEosgEAcANXniqemJioWbNm8X3YAACYhHuyAQBwIzNnztTly5dLrT916pQKCgpMSAQAgGehyAYAwI3ce++9Wrp0aan1y5cv17333mtCIgAAPAtFNgAAbmTr1q3q2rVrqfVdunTR1q1bTUgEAIBnocgGAMCNXLx4sczLxS9duqRffvnFhEQAAHgWimwAANxIhw4dNG/evFLr09PTFRsba0IiAAA8C08XBwDAjTz//POKj4/Xnj171L17d0lSRkaGtm/frs8//9zkdAAAuD9msgEAcCOdO3fW5s2bFRkZqeXLl+ujjz5SVFSU9u7dq1tvvdXseAAAuD1Ti+xNmzapd+/eioiIkMVi0erVq+22G4ahCRMmKDw8XDVq1FB8fLwOHjxoTlgAAKqJdu3aafHixfr222+1Y8cOzZ8/X9HR0WbHAgDAI5haZBcWFqpt27aaM2dOmdtffvllzZ49W+np6dq6datq1qyphIQEXbhwoYqTAgBQ/Vy4cEEFBQV2LwAAULlMvSe7V69e6tWrV5nbDMPQzJkzNW7cOPXt21eStGjRIoWGhmr16tV81ycAAGU4f/68xowZo+XLl+vkyZOlthcXF5uQCgAAz+Gy92RnZ2crLy9P8fHxtnXBwcHq2LGjNm/eXO6+v/3U/uLFi5UdFwAAl/DUU09p/fr1mjt3rvz9/fXWW29p0qRJioiI0KJFi8yOBwCA23PZIjsvL0+SFBoaarc+NDTUtu1qIiMjFRwcbHtNmTKl0nICAOBKPvroI73++usaMGCAfHx8dOutt2rcuHF68cUXtXjxYrPjAQDg9tzyK7yOHj0qq9VqW/b39zcxDQAAVefUqVNq3ry5JMlqterUqVOSpFtuuUUjR440MxoAAB7BZWeyw8LCJEn5+fl26/Pz823brsZqtdq9KLIBAJ6iefPmys7OliS1atVKy5cvl/TrDHft2rVNTAYAgGdw2SK7WbNmCgsLU0ZGhm1dQUGBtm7dqri4OBOTAQDguhITE7Vnzx5J0jPPPKM5c+YoICBAKSkpeuqpp0xOBwCA+zP1cvFz587p0KFDtuXs7GxlZWWpbt26aty4sUaPHq3nn39e0dHRatasmcaPH6+IiAj169fPvNAAALiwlJQU28/x8fH6/vvvtXPnTkVFRSkmJsbEZAAAeAZTi+wdO3aoa9eutuXU1FRJ0tChQ7VgwQKNGTNGhYWFeuSRR3T69GndcsstWrNmjQICAsyKDACAy7p06ZJ69uyp9PR0RUdHS5KaNGmiJk2amJwMAADPYWqR3aVLFxmGcdXtFotFkydP1uTJk6swFQAA1ZOvr6/27t1rdgwAADyay96TDQAAHHf//ffr7bffNjsGAAAeyy2/wquqfbjtfLnb+3QIrKIkAABPd/nyZc2fP19ffPGFYmNjVbNmTbvt06dPNykZAACegSIbAAA3sm/fPrVv316SdODAAbttFovFjEgAAHgUimwAANzADz/8oGbNmmnDhg1mRwEAwKNxTzYAAG4gOjpax48fty0PHDhQ+fn5JiYCAMAzUWQDAOAGfvttHZ9++qkKCwtNSgMAgOeiyAYAAAAAwEkosgEAcAMWi6XUg8140BkAAFWPB58BAOAGDMPQsGHD5O/vL0m6cOGCRowYUeorvFauXGlGPAAAPAZFNgAAbmDo0KF2y/fff79JSQAA8GwU2QAAuIF33nnH7AgAAEDckw0AAAAAgNNQZAMAAAAA4CQU2QAAAAAAOAlFNgAAAAAATkKRDQAAAACAk1BkAwAAAADgJBTZAAAAAAA4CUU2AAAAAABOQpENAADKNWfOHDVt2lQBAQHq2LGjtm3bdtW2b775pm699VbVqVNHderUUXx8fLntAQBwNxTZAADgqpYtW6bU1FSlpaVp165datu2rRISEnTs2LEy22/cuFGDBg3Shg0btHnzZkVGRqpHjx766aefqjg5AADmoMgGAABXNX36dA0fPlyJiYlq3bq10tPTFRgYqPnz55fZfvHixXr00UfVrl07tWrVSm+99ZZKSkqUkZFRxckBADAHRTYAAChTUVGRdu7cqfj4eNs6Ly8vxcfHa/PmzRXq4/z587p06ZLq1q1bbruCggK718WLF/9QdgAAzEKRDQAAynTixAkVFxcrNDTUbn1oaKjy8vIq1MfTTz+tiIgIu0K9LJGRkQoODra9pkyZcs25AQAwk4/ZAQAAgHuaOnWqli5dqo0bNyogIKDctkePHpXVarUt+/v7V3Y8AAAqBUU2AAAoU/369eXt7a38/Hy79fn5+QoLCyt337/97W+aOnWqvvjiC8XExPzue1mtVrsiGwCA6orLxQEAQJn8/PwUGxtr99CyKw8xi4uLu+p+L7/8sp577jmtWbNGN910U1VEBQDAZTCTDQAArio1NVVDhw7VTTfdpA4dOmjmzJkqLCxUYmKiJGnIkCFq2LCh7R7ql156SRMmTNCSJUvUtGlT273bQUFBCgoKMu04AACoKhTZAADgqgYOHKjjx49rwoQJysvLU7t27bRmzRrbw9BycnLk5fWfC+Pmzp2roqIi/elPf7LrJy0tTRMnTqzK6AAAmIIiGwAAlCs5OVnJycllbtu4caPd8pEjRyo/EAAALox7sgEAAAAAcBKKbAAAAAAAnIQiGwAAAAAAJ6HIBgAAAADASVy6yJ44caIsFovdq1WrVmbHAgAAAACgTC7/dPEbbrhBX3zxhW3Zx8flIwMAAAAAPJTLV6w+Pj4KCwszOwYAAAAAAL/LpS8Xl6SDBw8qIiJCzZs313333aecnByzIwEAAAAAUCaXnsnu2LGjFixYoJYtWyo3N1eTJk3Srbfeqn379qlWrVpX3a+goMBu2d/fX/7+/pUdFwAAAADg4Vx6JrtXr1665557FBMTo4SEBH366ac6ffq0li9fXu5+kZGRCg4Otr2mTJlSRYkBAAAAAJ7MpWeyf6t27dq67rrrdOjQoXLbHT16VFar1bbMLDYAAAAAoCq49Ez2b507d06HDx9WeHh4ue2sVqvdiyIbAAAAAFAVXLrIfvLJJ5WZmakjR47o66+/Vv/+/eXt7a1BgwaZHQ0AAAAAgFJc+nLxf/3rXxo0aJBOnjypBg0a6JZbbtGWLVvUoEEDs6MBAAAAAFCKSxfZS5cuNTsCAAAAAAAV5tKXiwMAAAAAUJ1QZAMAAAAA4CQU2QAAAAAAOAlFNgAAAAAATkKRDQAAAACAk1BkAwAAAADgJBTZAAAAAAA4CUU2AAAAAABOQpENAAAAAICTUGQDAAAAAOAkPmYH8CQfbjtf7vY+HQKrKAkAAAAAoDIwkw0AAAAAgJNQZAMAAAAA4CQU2QAAAAAAOAlFNgAAAAAATkKRDQAAAACAk1BkAwAAAADgJBTZAAAAAAA4CUU2AAAAAABOQpENAAAAAICTUGQDAAAAAOAkFNkAAAAAADgJRTYAAAAAAE5CkQ0AAAAAgJNQZAMAAAAA4CQU2QAAAAAAOImP2QFQ2ofbzpe7vU+HwCpKAgAAAABwBDPZAAAAAAA4CUU2AAAAAABOQpENAAAAAICTUGQDAAAAAOAkFNkAAAAAADgJRTYAAAAAAE5CkQ0AAAAAgJNQZAMAAAAA4CTVosieM2eOmjZtqoCAAHXs2FHbtm1zav8XL17UxIkTdfHiRaf2W5Wq+zFU9/wSx+AqOAbXwDG4F0fH4ffff1+tWrVSQECA2rRpo08//dSpedzh3Fwquqj33nxBl4o4BjNxDK6BY3ANHIPzuHyRvWzZMqWmpiotLU27du1S27ZtlZCQoGPHjjntPS5evKhJkyZV68G6uh9Ddc8vcQyugmNwDRyD+3B0HP766681aNAgPfTQQ9q9e7f69eunfv36ad++fU7L5A7n5lLRRS1960XT/xD8IzgG18AxuAaOwTW4yjG4fJE9ffp0DR8+XImJiWrdurXS09MVGBio+fPnmx0NAAC35+g4PGvWLPXs2VNPPfWUrr/+ej333HNq3769XnvttSpODgCAOVy6yC4qKtLOnTsVHx9vW+fl5aX4+Hht3rzZxGQAALi/axmHN2/ebNdekhISEhi3AQAew8fsAOU5ceKEiouLFRoaarc+NDRU33//fan2hmFIkn766ScVFBTY1vv7+8vf3/+q73Ol7X/vc8X5c+fL2e/y77apzHaf7vhPu/OFZyVJKzLzFVjzvO68KbBUm7K4Srvf5nelbBVtV92Ooaw21fUY/lt5/z1XFxyDa6jMY7jS55Vxy1U5Og5LUl5eXpnt8/Lyymx/LWP3tY7bv+5T9WN3WW2u/P/2yj/Nynal3bX05SrH8Ef64hgq99+Rirar7GOoinPKMVTuvyMVbVfeMfxRjozdLl1kO+rs2V9/ma1bt76m/SMjI50ZxxQP9bnO7Ah/SHXPL3EMrsId/nvmGFxDZR7D2bNnFRwcXGn9Vwd/ZOx2h3+/3OH/txyDa+AYXAPH4Boq8xgqMna7dJFdv359eXt7Kz8/3259fn6+wsLCSrWPiIjQ4cOH5evrK4vFYlv/ezPZAABUJcMwdPbsWUVERJgdpVyOjsOSFBYW5lB7xm4AQHXgyNjt0kW2n5+fYmNjlZGRoX79+kmSSkpKlJGRoeTk5FLtvby81Lx58ypOCQCA46rDDLaj47AkxcXFKSMjQ6NHj7atW7duneLi4spsz9gNAKguKjp2u3SRLUmpqakaOnSobrrpJnXo0EEzZ85UYWGhEhMTzY4GAIDb+71xeMiQIWrYsKGmTJkiSRo1apRuv/12TZs2TXfddZeWLl2qHTt2aN68eWYeBgAAVcbli+yBAwfq+PHjmjBhgvLy8tSuXTutWbOm1ENVAACA8/3eOJyTkyMvr/98WUmnTp20ZMkSjRs3Ts8++6yio6O1evVq3XjjjWYdAgAAVcqlv8LriuTkZP3444+6ePGitm7dqo4dOzqt7zlz5qhp06YKCAhQx44dtW3bNqf1XdkmTpwoi8Vi92rVqpXZscq1adMm9e7dWxEREbJYLFq9erXddsMwNGHCBIWHh6tGjRqKj4/XwYMHzQl7Fb93DMOGDSt1Xnr27GlO2KuYMmWKbr75ZtWqVUshISHq16+f9u/fb9fmwoULSkpKUr169RQUFKQBAwaUus/STBU5hi5dupQ6FyNGjDApcWlz585VTEyMrFarrFar4uLi9Nlnn9m2u/o5+L38rv77L8vUqVNlsVjsLnV29fNQFcobhzdu3KgFCxbYtb/nnnu0f/9+Xbx4Ufv27dOdd97p1DyM3VWLsdt8jNuuobqP2xJjd1WpFkV2ZVm2bJlSU1OVlpamXbt2qW3btkpISNCxY8fMjlZhN9xwg3Jzc22vL7/80uxI5SosLFTbtm01Z86cMre//PLLmj17ttLT07V161bVrFlTCQkJunDhQhUnvbrfOwZJ6tmzp915ee+996ow4e/LzMxUUlKStmzZonXr1unSpUvq0aOHCgsLbW1SUlL00Ucf6f3331dmZqZ+/vln3X333SamtleRY5Ck4cOH252Ll19+2aTEpTVq1EhTp07Vzp07tWPHDnXr1k19+/bVt99+K8n1z8Hv5Zdc+/f/W9u3b9cbb7yhmJgYu/Wufh48DWN31WPsNh/jtmuo7uO2xNhdZQwP1qFDByMpKcm2XFxcbERERBhTpkwxMVXFpaWlGW3btjU7xjWTZKxatcq2XFJSYoSFhRmvvPKKbd3p06cNf39/47333jMh4e/77TEYhmEMHTrU6Nu3ryl5rtWxY8cMSUZmZqZhGL/+3n19fY3333/f1ua7774zJBmbN282K2a5fnsMhmEYt99+uzFq1CjzQl2DOnXqGG+99Va1PAeG8Z/8hlG9fv9nz541oqOjjXXr1tnlrq7nwZ0xdpuLsds1MG67juo+bhsGY3dl8NiZ7KKiIu3cuVPx8fG2dV5eXoqPj9fmzZtNTOaYgwcPKiIiQs2bN9d9992nnJwcsyNds+zsbOXl5dmdk+DgYHXs2LFanRPp18snQ0JC1LJlS40cOVInT540O1K5zpw5I0mqW7euJGnnzp26dOmS3blo1aqVGjdu7LLn4rfHcMXixYtVv3593XjjjRo7dqzOnz9vRrzfVVxcrKVLl6qwsFBxcXHV7hz8Nv8V1eX3n5SUpLvuusvu9y1Vz/8W3Bljt+th7DYH47b5qvu4LTF2VyaXf/BZZTlx4oSKi4tLPUAtNDRU33//vUmpHNOxY0ctWLBALVu2VG5uriZNmqRbb71V+/btU61atcyO57C8vDxJKvOcXNlWHfTs2VN33323mjVrpsOHD+vZZ59Vr169tHnzZnl7e5sdr5SSkhKNHj1anTt3tj2YKC8vT35+fqpdu7ZdW1c9F2UdgyQNHjxYTZo0UUREhPbu3aunn35a+/fv18qVK01Ma++bb75RXFycLly4oKCgIK1atUqtW7dWVlZWtTgHV8svVY/fvyQtXbpUu3bt0vbt20ttq27/Lbg7xm7Xw9hd9Ri3zVXdx22JsbsqeGyR7Q569epl+zkmJkYdO3ZUkyZNtHz5cj300EMmJvNs9957r+3nNm3aKCYmRi1atNDGjRvVvXt3E5OVLSkpSfv27XP5ewLLc7VjeOSRR2w/t2nTRuHh4erevbsOHz6sFi1aVHXMMrVs2VJZWVk6c+aMVqxYoaFDhyozM9PsWBV2tfytW7euFr//o0ePatSoUVq3bp0CAgLMjgMPwNjtmqrT2M24ba7qPm5LjN1VwWMvF69fv768vb1LPWUuPz9fYWFhJqX6Y2rXrq3rrrtOhw4dMjvKNbnye3encyJJzZs3V/369V3yvCQnJ+vjjz/Whg0b1KhRI9v6sLAwFRUV6fTp03btXfFcXO0YynLliciudC78/PwUFRWl2NhYTZkyRW3bttWsWbOqzTm4Wv6yuOLvf+fOnTp27Jjat28vHx8f+fj4KDMzU7Nnz5aPj49CQ0OrxXnwFIzdroexu2oxbpuvuo/bEmN3VfDYItvPz0+xsbHKyMiwrSspKVFGRobdPQnVyblz53T48GGFh4ebHeWaNGvWTGFhYXbnpKCgQFu3bq2250SS/vWvf+nkyZMudV4Mw1BycrJWrVql9evXq1mzZnbbY2Nj5evra3cu9u/fr5ycHJc5F793DGXJysqSJJc6F79VUlKiixcvVotzUJYr+cviir//7t2765tvvlFWVpbtddNNN+m+++6z/Vwdz4O7Yux2PYzdVYNx2zXOQ1mq+7gtMXZXiip5vJqLWrp0qeHv728sWLDA+Oc//2k88sgjRu3atY28vDyzo1XIE088YWzcuNHIzs42vvrqKyM+Pt6oX7++cezYMbOjXdXZs2eN3bt3G7t37zYkGdOnTzd2795t/Pjjj4ZhGMbUqVON2rVrGx988IGxd+9eo2/fvkazZs2MX375xeTk/1HeMZw9e9Z48sknjc2bNxvZ2dnGF198YbRv396Ijo42Lly4YHZ0m5EjRxrBwcHGxo0bjdzcXNvr/PnztjYjRowwGjdubKxfv97YsWOHERcXZ8TFxZmY2t7vHcOhQ4eMyZMnGzt27DCys7ONDz74wGjevLlx2223mZz8P5555hkjMzPTyM7ONvbu3Ws888wzhsViMT7//HPDMFz/HJSXvzr8/q/mt09WdfXz4GkYu6seY7f5GLddQ3Uftw2DsbuqeHSRbRiG8eqrrxqNGzc2/Pz8jA4dOhhbtmwxO1KFDRw40AgPDzf8/PyMhg0bGgMHDjQOHTpkdqxybdiwwZBU6jV06FDDMH79KpDx48cboaGhhr+/v9G9e3dj//795ob+jfKO4fz580aPHj2MBg0aGL6+vkaTJk2M4cOHu9wff2Xll2S88847tja//PKL8eijjxp16tQxAgMDjf79+xu5ubnmhf6N3zuGnJwc47bbbjPq1q1r+Pv7G1FRUcZTTz1lnDlzxtzg/+XBBx80mjRpYvj5+RkNGjQwunfvbhuoDcP1z0F5+avD7/9qfjtQu/p58ESM3VWLsdt8jNuuobqP24bB2F1VLIZhGM6fHwcAAAAAwPN47D3ZAAAAAAA4G0U2AAAAAABOQpENAAAAAICTUGQDAAAAAOAkFNkAAAAAADgJRTYAAAAAAE5CkQ0AAAAAgJNQZAMAAAAA4CQU2QAkSRs3bpTFYtHp06f/UD/Dhg1Tv379nJIJAAAAqG4osoFqZtiwYbJYLLJYLPLz81NUVJQmT56sy5cv29oYhqF58+apY8eOCgoKUu3atXXTTTdp5syZOn/+fJn9durUSbm5uQoODq6qQwEAwC106dJFo0ePdnq/hmHokUceUd26dWWxWJSVlVVp7wXAeSiygWqoZ8+eys3N1cGDB/XEE09o4sSJeuWVV2zbH3jgAY0ePVp9+/bVhg0blJWVpfHjx+uDDz7Q559/Xmaffn5+CgsLk8ViqarDAADA5V35YPtqr4kTJ1bae69Zs0YLFizQxx9/rNzcXN14441auXKlnnvuuWvuszKL9IpMBEhSXl6eHnvsMTVv3lz+/v6KjIxU7969lZGRUSm5gKpGkQ1UQ/7+/goLC1OTJk00cuRIxcfH68MPP5QkLV++XIsXL9Z7772nZ599VjfffLOaNm2qvn37av369eratWuZff72cvEFCxaodu3aWrt2ra6//noFBQXZivsriouLlZqaqtq1a6tevXoaM2aMDMOw67ekpERTpkxRs2bNVKNGDbVt21YrVqyQ9Osn9PHx8UpISLDtd+rUKTVq1EgTJkxw9q8NAACH5ebm2l4zZ86U1Wq1W/fkk09W2nsfPnxY4eHh6tSpk8LCwuTj46O6deuqVq1aZbYvKiqqtCwV9XsTAUeOHFFsbKzWr1+vV155Rd98843WrFmjrl27KikpycTkgPNQZANuoEaNGraBdfHixWrZsqX69u1bqp3FYnHocvDz58/rb3/7m/7+979r06ZNysnJsftjYtq0aVqwYIHmz5+vL7/8UqdOndKqVavs+pgyZYoWLVqk9PR0ffvtt0pJSdH999+vzMxMWSwWLVy4UNu3b9fs2bMlSSNGjFDDhg0psgEALiEsLMz2Cg4OlsVisVsXFBQk6dcPlceMGaO6desqLCys1Ax3eR86l2XYsGF67LHHlJOTI4vFoqZNm0qyn4nu0qWLkpOTNXr0aNWvX18JCQmSpBUrVqhNmzaqUaOG6tWrp/j4eBUWFmrYsGHKzMzUrFmzbDPOR44cKfP9Dx8+LIvFoo8//ljdu3dXYGCgWrZsqa1bt5b7+ypvIkCSHn30UVksFm3btk0DBgzQddddpxtuuEGpqanasmVLuX0D1YWP2QEAXDvDMJSRkaG1a9fqsccekyQdPHhQLVu2dEr/ly5dUnp6ulq0aCFJSk5O1uTJk23bZ86cqbFjx+ruu++WJKWnp2vt2rW27RcvXtSLL76oL774QnFxcZKk5s2b68svv9Qbb7yh22+/XQ0bNtQbb7yhIUOGKC8vT59++ql2794tHx/+9wQAqD4WLlyo1NRUbd26VZs3b9awYcPUuXNn3XHHHZJ+/dD53XffVXp6uqKjo7Vp0ybdf//9atCggW6//fZS/c2aNUstWrTQvHnztH37dnl7e1/1fUeOHKmvvvpK0q8z74MGDdLLL7+s/v376+zZs/rHP/4hwzA0a9YsHThwQDfeeKNtPG/QoEGZ/e7Zs0cWi0XTp0/XhAkT1LBhQz366KN65plntGHDhgr/XmrUqKGTJ09K+vVqtTVr1uiFF15QzZo1S7WtXbt2hfsFXBl/xQLV0Mcff6ygoCBdunRJJSUlGjx4sO0T899erv1HBAYG2gpsSQoPD9exY8ckSWfOnFFubq46duxo2+7j46ObbrrJluHQoUM6f/687Q+MK4qKivT//t//sy3fc889WrVqlaZOnaq5c+cqOjraaccAAEBViImJUVpamiQpOjpar732mjIyMnTHHXdU6EPn3woODlatWrXk7e2tsLCwq75vdHS0Xn75Zdvyrl27dPnyZd19991q0qSJJKlNmza27X5+fgoMDCy3T+nXIrt27dpatmyZrRDv06eP3njjjQr9PsqaCDh06JAMw1CrVq0q1AdQXVFkA9VQ165dNXfuXPn5+SkiIsJu1ve6667T999/75T38fX1tVu2WCwOFfHnzp2TJH3yySdq2LCh3TZ/f3/bz+fPn9fOnTvl7e2tgwcP/oHEAACYIyYmxm75vz+YruiHztciNjbWbrlt27bq3r272rRpo4SEBPXo0UN/+tOfVKdOHYf63bNnj/r27Ws3052dna2oqKhy96uqiQDAlXFPNlAN1axZU1FRUWrcuHGpy6oHDx6sAwcO6IMPPii1n2EYOnPmjFMyBAcHKzw83O7erMuXL2vnzp225datW8vf3185OTmKioqye0VGRtraPfHEE/Ly8tJnn32m2bNna/369U7JCABAVSnrg+mSkhJJ9h86Z2Vl2V7//Oc/y70vuyJ+e9m1t7e31q1bp88++0ytW7fWq6++qpYtWyo7O9uhfvfs2WObdb8iKytL7dq1K3e/rl27KisrSwcPHtQvv/yihQsX2jJGR0fLYrE4bTIAcFUU2YCb+fOf/6yBAwdq0KBBevHFF7Vjxw79+OOP+vjjjxUfH+/QfVS/Z9SoUZo6dapWr16t77//Xo8++qjt6eSSVKtWLT355JNKSUnRwoULdfjwYe3atUuvvvqqFi5cKOnXPzjmz5+vxYsX64477tBTTz2loUOH6t///rfTcgIAYKaKfujsLBaLRZ07d9akSZO0e/du+fn52R5M6ufnp+Li4nL3P3PmjI4cOVJqlr0iRXZ5EwF169ZVQkKC5syZo8LCwlL7/vffEEB1xuXigJuxWCxasmSJ5s2bp/nz5+uFF16Qj4+PoqOjNWTIENuTR53hiSeeUG5uroYOHSovLy89+OCD6t+/v91s+XPPPacGDRpoypQp+uGHH1S7dm21b99ezz77rI4fP66HHnpIEydOVPv27SVJkyZN0ueff64RI0Zo2bJlTssKAIBZ/vtD55KSEt1yyy06c+aMvvrqK1mtVg0dOtRp77V161ZlZGSoR48eCgkJ0datW3X8+HFdf/31kqSmTZtq69atOnLkiIKCglS3bl15ednPu+3du1c+Pj5293L/+OOP+ve///27RfbvmTNnjjp37qwOHTpo8uTJiomJ0eXLl7Vu3TrNnTtX33333R/qH3AFFNlANbNgwYLfbePl5aURI0ZoxIgRFe63S5cudvdKDRs2TMOGDbNr069fP7s2Pj4+mjlzpmbOnHnVfi0Wi0aNGqVRo0aVuT0vL89u2dfXVzt27KhwbgAAqoPyPnR2JqvVqk2bNmnmzJkqKChQkyZNNG3aNPXq1UuS9OSTT2ro0KFq3bq1fvnlF2VnZ9u+HuyKPXv2qGXLlgoICLCt2717t2rXrl2qraOaN2+uXbt26YUXXrB9WN+gQQPFxsZq7ty5f6hvwFVYDJ5AAAAAAACAU3BPNgAAAAAATkKRDQAAAACAk1BkAwAAAADgJBTZAAAAAAA4CUU2AAAAAABOQpENAAAAAICTUGQDAAAAAOAkFNkAAAAAADgJRTYAAAAAAE5CkQ0AAAAAgJNQZAMAAAAA4CQU2QAAAAAAOMn/BzAJf4dzmIp2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(10,4))\n",
    "importance = pca.explained_variance_\n",
    "cumulateive_importance = np.cumsum(importance)/np.sum(importance)\n",
    "idx = np.arange(1,1+len(importance))\n",
    "ax1.bar(idx,importance, alpha=0.5, color='cornflowerblue')\n",
    "ax1.set_xlabel(\"PC index\")\n",
    "ax1.set_ylabel(\"Variance\")\n",
    "# ax1.set_yscale(\"log\")\n",
    "ax2.bar(idx,cumulateive_importance, alpha=0.5, color='cornflowerblue')\n",
    "ax2.set_xlabel(r\"The first $n$ PC\")\n",
    "ax2.set_ylabel(\"Fraction of total variance\")\n",
    "plt.tight_layout()\n",
    "ax1.tick_params(direction=\"in\", which='both')\n",
    "ax2.tick_params(direction=\"in\", which='both')\n",
    "plt.savefig(path+\"/plots/running_coupling/PC_importance_2obs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "924edd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69779203 0.88645334 0.95355582 0.98403559 0.98619477 0.98821056\n",
      " 0.98959443 0.99081906 0.99175254 0.99262712 0.9934485  0.99420272\n",
      " 0.99482612 0.99539828 0.99594155 0.99644937 0.99691673 0.99729396\n",
      " 0.99764002 0.99795654 0.99822802 0.99849129 0.99871699 0.99891559\n",
      " 0.9990875  0.99924762 0.99938118 0.9994944  0.99959241 0.9996801\n",
      " 0.99975669 0.99981092 0.99985968 0.99989774 0.99993493 0.99996351\n",
      " 0.99998656 0.99999482 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(cumulateive_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c59d8f59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformed = SS.fit_transform(Y_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73a01b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(pc_tf_data.T[0], pc_tf_data.T[1], label='PCA', color='cornflowerblue', alpha=0.5)\n",
    "plt.scatter(transformed.T[0], transformed.T[1], label='original', color='tomato', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tick_params(direction=\"in\", which='both')\n",
    "plt.savefig('PCA_orthogonal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d048d415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Training PC # 1\n",
      "GPR score: 0.816\n",
      "time: 0.085 seconds\n",
      "-----------------\n",
      "Training PC # 2\n",
      "GPR score: 0.353\n",
      "time: 0.060 seconds\n",
      "-----------------\n",
      "Training PC # 3\n",
      "GPR score: 0.652\n",
      "time: 0.049 seconds\n",
      "-----------------\n",
      "Training PC # 4\n",
      "GPR score: 0.515\n",
      "time: 0.063 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianyu/.local/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 280.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/tianyu/.local/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__k2__length_scale is close to the specified upper bound 235.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/tianyu/.local/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 280.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/tianyu/.local/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 1 of parameter k1__k2__length_scale is close to the specified lower bound 0.5599999999999999. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/tianyu/.local/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 2 of parameter k1__k2__length_scale is close to the specified upper bound 43.99999999999999. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/tianyu/.local/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 280.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/tianyu/.local/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 2 of parameter k1__k2__length_scale is close to the specified upper bound 43.99999999999999. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/tianyu/.local/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 280.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/tianyu/.local/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 1 of parameter k1__k2__length_scale is close to the specified upper bound 280.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/tianyu/.local/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 2 of parameter k1__k2__length_scale is close to the specified upper bound 43.99999999999999. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/tianyu/.local/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__k2__length_scale is close to the specified lower bound 0.47000000000000003. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "EMU = path+'/data/running_coupling/emulators.dat'\n",
    "Emulators=[]\n",
    "for i in range(0,Npc):\n",
    "    start_time = time.time()\n",
    "    kernel=1*krnl.RBF(length_scale=design_ptp,\n",
    "                          length_scale_bounds=np.outer(design_ptp, (1./5, 1e2))) + krnl.WhiteKernel(noise_level=.01, \n",
    "                                  noise_level_bounds=(1e-4, 1e4))\n",
    "    print(\"-----------------\")\n",
    "    print(\"Training PC #\",i+1)\n",
    "    GPR=gpr(kernel=kernel,n_restarts_optimizer=0)\n",
    "    GPR.fit(design, pc_tf_data[:,i].reshape(-1,1))\n",
    "    print('GPR score: {:1.3f}'.format(GPR.score(design,pc_tf_data[:,i])) )\n",
    "    print(\"time: {:1.3f} seconds\".format(time.time() - start_time))\n",
    "    Emulators.append(GPR)\n",
    "    \n",
    "with open(EMU, \"wb\") as f:\n",
    "    pickle.dump(Emulators,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0f9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdim = 5\n",
    "use_NL = True\n",
    "def predict_observables(model_parameters, diag_std=False):\n",
    "    \"\"\"Predicts the observables for any model parameter value using the trained emulators.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Theta_input : Model parameter values.\n",
    "    Return\n",
    "    ------\n",
    "    Mean value and full error covaraiance matrix of the prediction is returened. \"\"\"\n",
    "\n",
    "    mean=[]\n",
    "    variance=[]\n",
    "    theta=np.array(model_parameters).flatten()\n",
    "    if len(theta)!=Xdim:\n",
    "        raise TypeError('The input model_parameters array does not have the right dimensions')\n",
    "    else: \n",
    "        theta=np.array(theta).reshape(1,Xdim)\n",
    "        for i in range(Npc):\n",
    "            mn,std=Emulators[i].predict(theta, return_std=True)\n",
    "            mean.append(mn)\n",
    "            variance.append(std**2)\n",
    "    mean=np.array(mean).reshape(1,-1)\n",
    "    inverse_transformed_mean = mean@inverse_tf_matrix + np.array(SS.mean_).reshape(1,-1)    \n",
    "    variance_matrix = np.diag(np.array(variance).flatten())\n",
    "    inverse_transformed_variance = np.einsum('ik,kl,lj-> ij', inverse_tf_matrix.T, variance_matrix, inverse_tf_matrix, \n",
    "                                             optimize=False)\n",
    "    if use_NL:\n",
    "        inverse_transformed_mean = inverse_transformed_mean**2\n",
    "        inverse_transformed_variance *= np.outer(2.*inverse_transformed_mean[0]**.5, \n",
    "                                                 2.*inverse_transformed_mean[0]**.5)\n",
    "    if diag_std:\n",
    "        return inverse_transformed_mean[0], np.sqrt(np.diag(inverse_transformed_variance))\n",
    "    else:\n",
    "        return inverse_transformed_mean[0], inverse_transformed_variance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation = np.array([[0, 0, 0.3, 1.6, 0.25]])\n",
    "\n",
    "# Next, get the emulator prediction and uncertainty\n",
    "A = np.array([predict_observables(it, diag_std=True) for it in X_validation])\n",
    "Y_predicted = A[:,0,:]\n",
    "Y_std = A[:,1,:]\n",
    "np.savetxt(path+'/data/running_coupling/data_predicted', Y_predicted)\n",
    "np.savetxt(path+'/data/running_coupling/data_predicted_err', Y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe161fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pT1 = np.array([8.25, 8.75, 9.25, 9.75, 11, 13, 15, 17, 19])\n",
    "Nc1 = 9\n",
    "pT3 = np.array([10.75, 12.35, 14.15, 16.2, 18.6, 21.35, 24.45, 28.05, 33.85, 42.6, 53.65, 67.55, 85.05, 106.9, 134.5])\n",
    "Nc2 = 9 + Nc1\n",
    "pT2 = np.array([8.25, 8.75, 9.25, 9.75, 11, 13, 15, 17, 19])\n",
    "Nc3 = 15 + Nc2\n",
    "pT4 = np.array([10.75, 12.35, 14.15, 16.2, 18.6, 21.35, 24.45, 28.05, 33.85, 42.6, 53.65, 67.55, 85.05, 106.9])\n",
    "Nc4 = 14 + Nc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ec7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_validation = np.array([np.loadtxt(path+'/data/running_coupling/data_val_4obs')])\n",
    "Y_validation_err = np.array([np.loadtxt(path+'/data/running_coupling/data_val_err_4obs')])\n",
    "print(Y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7550df",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_samp = np.array([[-0.8, 0., 2.], [-0.8, 0., 2.], [0.16, 0.3, 0.6], [1.15, 1.6, 3.5], [0.1, 0.25, 0.4]])\n",
    "ParameterLabels = ['$\\\\beta_1$', '$\\\\beta_2$', '$T^*$', '$Q_0$', '$\\\\alpha^{inel}_{s, hard}$']\n",
    "colors = ['r', 'b', 'g']\n",
    "\n",
    "fig, axes = plt.subplots(5,4, figsize=(16,16))\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "labels = r\"$R_{AA}$\"\n",
    "\n",
    "for i, color in enumerate(colors): \n",
    "    X_validation = np.array([param_samp.T[1]])\n",
    "\n",
    "    \n",
    "    for j, param_label in enumerate(ParameterLabels): \n",
    "        X_validation[0, j] = param_samp[j, i]\n",
    "        A = np.array([predict_observables(it, diag_std=True) for it in X_validation])\n",
    "        Y_predicted = A[:,0,:]\n",
    "        Y_std = A[:,1,:]\n",
    "        for k, (mean, std) in enumerate(zip(Y_predicted, Y_std)):\n",
    "            label = param_label+'=%.2f' %param_samp[j, i]\n",
    "            axes[j, 0].fill_between(pT1,mean[:Nc1]-std[:Nc1],mean[:Nc1]+std[:Nc1],color=color,alpha=.2, label=label)\n",
    "        for k, (mean, std) in enumerate(zip(Y_predicted, Y_std)):\n",
    "            label = param_label+'=%.2f' %param_samp[j, i]\n",
    "            axes[j, 1].fill_between(pT2,mean[Nc1:Nc2]-std[Nc1:Nc2],mean[Nc1:Nc2]+std[Nc1:Nc2],color=color,alpha=.2, label=label)\n",
    "        for k, (mean, std) in enumerate(zip(Y_predicted, Y_std)):\n",
    "            label = param_label+'=%.2f' %param_samp[j, i]\n",
    "            axes[j, 2].fill_between(pT3,mean[Nc2:Nc3]-std[Nc2:Nc3],mean[Nc2:Nc3]+std[Nc2:Nc3],color=color,alpha=.2, label=label)\n",
    "        for k, (mean, std) in enumerate(zip(Y_predicted, Y_std)):\n",
    "            label = param_label+'=%.2f' %param_samp[j, i]\n",
    "            axes[j, 3].fill_between(pT4,mean[Nc3:Nc4]-std[Nc3:Nc4],mean[Nc3:Nc4]+std[Nc3:Nc4],color=color,alpha=.2, label=label)\n",
    "            \n",
    "        # label = 'Model calc.' if i == 0 else ''\n",
    "        axes[j, 0].errorbar(pT1, Y_validation[0][:Nc1], Y_validation_err[0][:Nc1], color='black')\n",
    "        axes[j, 1].errorbar(pT2, Y_validation[0][Nc1:Nc2], Y_validation_err[0][Nc1:Nc2], color='black')\n",
    "        axes[j, 2].errorbar(pT3, Y_validation[0][Nc2:Nc3], Y_validation_err[0][Nc2:Nc3], color='black')\n",
    "        axes[j, 3].errorbar(pT4, Y_validation[0][Nc3:Nc4], Y_validation_err[0][Nc3:Nc4], color='black')\n",
    "        # axes[j, 0].set_xlabel(\"$p_T$ (GeV)\")\n",
    "        axes[j, 0].set_ylabel(labels)\n",
    "        axes[j, 0].legend()\n",
    "        axes[j, 0].set_ylim(0, 1.5)\n",
    "        axes[j, 0].set_xlim(8.25, 19)\n",
    "        # axes[j, 1].set_xlabel(\"$p_T$ (GeV)\")\n",
    "        # axes[j, 1].set_ylabel(labels)\n",
    "        axes[j, 1].legend()\n",
    "        axes[j, 1].set_ylim(0, 1.5)\n",
    "        axes[j, 1].set_xlim(8.25, 19)\n",
    "        # axes[j, 2].set_xlabel(\"$p_T$ (GeV)\")\n",
    "        # axes[j, 2].set_ylabel(labels)\n",
    "        axes[j, 2].legend()\n",
    "        axes[j, 2].set_ylim(0, 1.5)\n",
    "        axes[j, 2].set_xlim(10.75, 106.9)\n",
    "        # axes[j, 3].set_xlabel(\"$p_T$ (GeV)\")\n",
    "        # axes[j, 3].set_ylabel(labels)\n",
    "        axes[j, 3].legend()\n",
    "        axes[j, 3].set_ylim(0, 1.5)\n",
    "        axes[j, 3].set_xlim(10.75, 106.9)\n",
    "        # axes[j, 0].tick_params(axis='y', which='both', labelleft=False)\n",
    "        axes[j, 1].tick_params(axis='y', which='both', labelleft=False)\n",
    "        axes[j, 2].tick_params(axis='y', which='both', labelleft=False)\n",
    "        axes[j, 3].tick_params(axis='y', which='both', labelleft=False)\n",
    "        axes[j, 0].tick_params(direction=\"in\", which='both')\n",
    "        axes[j, 1].tick_params(direction=\"in\", which='both')\n",
    "        axes[j, 2].tick_params(direction=\"in\", which='both')\n",
    "        axes[j, 3].tick_params(direction=\"in\", which='both')\n",
    "axes[4, 0].set_xlabel(\"$p_T$ (GeV)\")\n",
    "axes[4, 1].set_xlabel(\"$p_T$ (GeV)\")\n",
    "axes[4, 2].set_xlabel(\"$p_T$ (GeV)\")\n",
    "axes[4, 3].set_xlabel(\"$p_T$ (GeV)\")\n",
    "\n",
    "\n",
    "# titles = r\"centrality 40-50%\", r\"centrality 40-50%\"\n",
    "# titles = r\"Au+Au 200GeV, centrality 0-10%\"\n",
    "# for ax, label, title in zip(axes, labels, titles):\n",
    "# axes.set_xlabel(\"$p_T$ (GeV)\")\n",
    "# axes.set_ylabel(labels)\n",
    "# axes.legend()\n",
    "# axes.set_ylim(0, 0.5)\n",
    "axes[0, 0].set_title(r\"Au+Au 200GeV, centrality 0-10%\")\n",
    "axes[0, 1].set_title(r\"Pb+Pb 2760GeV, centrality 0-5%\")\n",
    "axes[0, 2].set_title(r\"Au+Au 200GeV, centrality 20-30%\")\n",
    "axes[0, 3].set_title(r\"Pb+Pb 2760GeV, centrality 30-40%\")\n",
    "\n",
    "# plt.tight_layout(True)\n",
    "plt.savefig(path+\"/plots/running_coupling/Emulator_validation_2pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52788eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emulator validation\n",
    "np.random.seed(9)\n",
    "# X_validation = design_min + np.random.rand(2, Xdim)*design_ptp\n",
    "# X_validation = np.array([design[0]])\n",
    "# X_validation = np.array([design[0]])\n",
    "\n",
    "# Next, get the emulator prediction and uncertainty\n",
    "X_validation = np.array([[0, 0, 0.3, 1.6, 0.25]])\n",
    "A = np.array([predict_observables(it, diag_std=True) for it in X_validation])\n",
    "Y_predicted = A[:,0,:]\n",
    "Y_std = A[:,1,:]\n",
    "# print(Y_predicted.shape)\n",
    "\n",
    "\n",
    "# Model calculation at these two points\n",
    "# Y_validation = np.array([np.concatenate(ToyModel(param)) for param in X_validation])\n",
    "# print(Y_validation.shape)\n",
    "# Y_validation = np.array([simulation[0]])\n",
    "Y_validation = np.array([np.loadtxt(path+'/data/running_coupling/data_val_4obs')])\n",
    "Y_validation_err = np.array([np.loadtxt(path+'/data/running_coupling/data_val_err_4obs')])\n",
    "# Y_validation_err = np.array([simulation_err[0]])\n",
    "\n",
    "labels = r\"$R_{AA}^{h^\\pm}$\"\n",
    "\n",
    "# plot the prediction + uncertainty band with the true model caluclation\n",
    "fig, axes = plt.subplots(2,2, figsize=(8,5))\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "for i, (mean, std) in enumerate(zip(Y_predicted, Y_std)):\n",
    "    label = 'GP emulated' if i==0 else''\n",
    "    axes[0, 0].fill_between(pT1,mean[:Nc1]-std[:Nc1],mean[:Nc1]+std[:Nc1],color='tomato',alpha=.5, label=label)\n",
    "    axes[1, 0].fill_between(pT2,mean[Nc1:Nc2]-std[Nc1:Nc2],mean[Nc1:Nc2]+std[Nc1:Nc2],color='tomato',alpha=.5, label=label)\n",
    "    axes[0, 1].fill_between(pT3,mean[Nc2:Nc3]-std[Nc2:Nc3],mean[Nc2:Nc3]+std[Nc2:Nc3],color='tomato',alpha=.5, label=label)\n",
    "    axes[1, 1].fill_between(pT4,mean[Nc3:Nc4]-std[Nc3:Nc4],mean[Nc3:Nc4]+std[Nc3:Nc4],color='tomato',alpha=.5, label=label)\n",
    "    # axes[1].fill_between(pT,mean[Nc:]-std[Nc:],mean[Nc:]+std[Nc:],color='r',alpha=.5, label=label)\n",
    "for i, ym, ym_err in zip(range(len(Y_validation)), Y_validation, Y_validation_err):\n",
    "    label = 'Model calc.' if i==0 else''\n",
    "    axes[0, 0].errorbar(pT1, ym[:Nc1], yerr=ym_err[:Nc1], label=label)\n",
    "    axes[1, 0].errorbar(pT2, ym[Nc1:Nc2], yerr=ym_err[Nc1:Nc2], label=label)\n",
    "    axes[0, 1].errorbar(pT3, ym[Nc2:Nc3], yerr=ym_err[Nc2:Nc3], label=label)\n",
    "    axes[1, 1].errorbar(pT4, ym[Nc3:Nc4], yerr=ym_err[Nc3:Nc4], label=label)\n",
    "    \n",
    "    # axes[1].errorbar(pT, ym[Nc:], yerr=ym_err[Nc:], label=label)\n",
    "    # axes[0, 0].set_xlabel(\"$p_T$ (GeV)\")\n",
    "    axes[0, 0].set_ylabel(labels)\n",
    "    # axes[0, 0].legend()\n",
    "    axes[0, 0].set_ylim(0, 1.1)\n",
    "    axes[0, 0].set_xlim(8.25, 19)\n",
    "    axes[0, 0].text(9, 0.9, 'Au+Au 200GeV, 0-10% centrality')\n",
    "    axes[1, 0].set_ylabel(labels)\n",
    "    # axes[1, 0].legend()\n",
    "    axes[1, 0].set_ylim(0, 1.1)\n",
    "    axes[1, 0].set_xlim(8.25, 19)\n",
    "    axes[1, 0].set_xlabel(\"$p_T$ (GeV)\")\n",
    "    axes[1, 0].text(9, 0.9, 'Au+Au 200GeV, 20-30% centrality')\n",
    "    # axes[0, 1].set_ylabel(labels)\n",
    "    # axes[0, 1].legend()\n",
    "    axes[0, 1].set_ylim(0, 1.1)\n",
    "    axes[0, 1].set_xlim(10, 106.5)\n",
    "    axes[0, 1].text(15, 0.9, 'Pb+Pb 2760GeV, 0-5% centrality')\n",
    "    # axes[0, 0].set_ylabel(labels)\n",
    "    axes[1, 1].legend(loc='lower right')\n",
    "    axes[1, 1].set_ylim(0, 1.1)\n",
    "    axes[1, 1].set_xlim(10, 106.5)\n",
    "    axes[1, 1].text(15, 0.9, 'Pb+Pb 2760GeV, 30-40% centrality')\n",
    "    axes[1, 1].set_xlabel(\"$p_T$ (GeV)\")\n",
    "    axes[0, 0].tick_params(direction=\"in\", which='both')\n",
    "    axes[1, 0].tick_params(direction=\"in\", which='both')\n",
    "    axes[0, 1].tick_params(direction=\"in\", which='both')\n",
    "    axes[1, 1].tick_params(direction=\"in\", which='both')\n",
    "    axes[0, 1].tick_params(axis='y', which='both', labelleft=False)\n",
    "    axes[1, 1].tick_params(axis='y', which='both', labelleft=False)\n",
    "\n",
    "\n",
    "# Add labels\n",
    "# labels = r\"$R_{AA}$\", r\"$R_{AA}$\", r\"$\"\n",
    "\n",
    "# titles = r\"centrality 40-50%\", r\"centrality 40-50%\"\n",
    "titles = r\"centrality 0-10%\"\n",
    "# for ax, label, title in zip(axes, labels, titles):\n",
    "\n",
    "# axes.set_title(titles)\n",
    "# plt.tight_layout(True)\n",
    "plt.savefig(path+\"/plots/running_coupling/Emulator_validation_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a22cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# design = np.loadtxt(path+'/data/running_coupling/lhd_sampling_5d.txt')\n",
    "x = np.arange(0., 1.5, 0.001)\n",
    "\n",
    "predicted_combine = []\n",
    "data_combine = []\n",
    "size_list = [9, 9, 15, 14]\n",
    "Nc_list = [0, Nc1, Nc2, Nc3, Nc4]\n",
    "lim_list = [(0.02, 0.8), (0.15, 1), (0.05, 1.1), (0.32, 1.5)]\n",
    "# plt.figure(figsize=(6, 6))\n",
    "label_list = ['$R_{AA}^{h^{\\pm}}$, Au+Au 200GeV, 0-10%', '$R_{AA}^{h^{\\pm}}$, Au+Au 200GeV, 20-30%', '$R_{AA}^{h^{\\pm}}$, Pb+Pb 2760GeV, 0-5%', '$R_{AA}^{h^{\\pm}}$, Pb+Pb 2760GeV, 30-40%']\n",
    "\n",
    "fig, axes = plt.subplots(2,2, figsize=(12, 12),dpi=500)\n",
    "\n",
    "for i in range(len(design)): \n",
    "    design_new = np.concatenate((design[:i], design[i+1:]), axis=0)\n",
    "    Y_model_new = np.concatenate((Y_model[:i], Y_model[i+1:]), axis=0)\n",
    "    \n",
    "    Emulators=[]\n",
    "    pc_tf_data_new = pca.fit_transform(SS.fit_transform(Y_model_new)) [:,:Npc]\n",
    "    for k in range(Npc):\n",
    "        kernel=1*krnl.RBF(length_scale=design_ptp,\n",
    "                          length_scale_bounds=np.outer(design_ptp, (1./5, 1e2))) + krnl.WhiteKernel(noise_level=.01, \n",
    "                                  noise_level_bounds=(1e-4, 1e4))\n",
    "        GPR=gpr(kernel=kernel,n_restarts_optimizer=0)\n",
    "        GPR.fit(design_new, pc_tf_data_new[:,k].reshape(-1,1))\n",
    "        Emulators.append(GPR)\n",
    "        \n",
    "        \n",
    "    mean=[]\n",
    "    theta=np.array(design[i]).flatten()\n",
    "    theta=np.array(theta).reshape(1,Xdim)\n",
    "    for k in range(Npc):\n",
    "        mn=Emulators[k].predict(theta)\n",
    "        mean.append(mn)\n",
    "    mean=np.array(mean).reshape(1,-1)\n",
    "    inverse_transformed_mean = mean@inverse_tf_matrix + np.array(SS.mean_).reshape(1,-1)\n",
    "    inverse_transformed_mean = inverse_transformed_mean**2\n",
    "    A = inverse_transformed_mean[0]\n",
    "    Y_predicted = [A]\n",
    "    \"\"\"\n",
    "    A = np.array([predict_observables(it, diag_std=True) for it in [design[i]]])\n",
    "    Y_predicted = A[:,0,:]\n",
    "    Y_std = A[:,1,:]\n",
    "    # kernel=1*krnl.RBF(length_scale=design_ptp, length_scale_bounds=np.outer(design_ptp, (1./5, 1e2))) + krnl.WhiteKernel(noise_level=.01, noise_level_bounds=(1e-4, 1e4))\n",
    "    # GPR=gpr(kernel=kernel,n_restarts_optimizer=0)\n",
    "    # GPR.fit(design_new, Y_model_new)\n",
    "    # Y_predicted, Y_std = GPR.predict([design[i]], return_std=True)\n",
    "    \"\"\"\n",
    "    predicted_combine.append(Y_predicted[0])\n",
    "    data_combine.append(Y_model[i]**2)\n",
    "    for j, ax, size in zip(range(4), axes.flat, size_list): \n",
    "        t = np.arange(size)\n",
    "        ax.scatter(Y_model[i][Nc_list[j]:Nc_list[j+1]]**2, Y_predicted[0][Nc_list[j]:Nc_list[j+1]], c=t, alpha=0.5, cmap=cm.twilight_shifted)\n",
    "        ax.plot(x, x, color='black')\n",
    "        ax.tick_params(direction=\"in\", which='both')\n",
    "        ax.set_xlim(lim_list[j])\n",
    "        ax.set_ylim(lim_list[j])\n",
    "        ax.text(lim_list[j][0]+0.05, lim_list[j][1]-0.1, label_list[j])\n",
    "        ax.set_xlabel('model calculation')\n",
    "        ax.set_ylabel('emulator prediction')\n",
    "plt.savefig(path+'/plots/running_coupling/model-emulator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_combine = np.array(predicted_combine)\n",
    "data_combine = np.array(data_combine)\n",
    "print(data_combine.shape)\n",
    "diff_combine_1 = []\n",
    "diff_combine_2 = []\n",
    "diff_combine_3 = []\n",
    "diff_combine_4 = []\n",
    "\n",
    "for i in range(len(predicted_combine)): \n",
    "    for j in range(Nc1): \n",
    "        diff_combine_1.append((predicted_combine[i, j] - data_combine[i, j]) / data_combine[i, j])\n",
    "    for j in range(Nc1, Nc2): \n",
    "        diff_combine_2.append((predicted_combine[i, j] - data_combine[i, j]) / data_combine[i, j])\n",
    "    for j in range(Nc2, Nc3): \n",
    "        diff_combine_3.append((predicted_combine[i, j] - data_combine[i, j]) / data_combine[i, j])\n",
    "    for j in range(Nc3, Nc4): \n",
    "        diff_combine_4.append((predicted_combine[i, j] - data_combine[i, j]) / data_combine[i, j])\n",
    "\n",
    "bins = np.arange(-0.1, 0.1, 0.02)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.hist(diff_combine_1, bins=20, histtype='step', color=sns.color_palette(\"Set2\")[0], label='$R_{AA}^{h^{\\pm}}$, Au+Au, 0-10%', density=True)\n",
    "plt.hist(diff_combine_2, bins=20, histtype='step', color=sns.color_palette(\"Set2\")[1], label='$R_{AA}^{h^{\\pm}}$, Au+Au, 20-30%', density=True)\n",
    "plt.hist(diff_combine_3, bins=20, histtype='step', color=sns.color_palette(\"Set2\")[2], label='$R_{AA}^{h^{\\pm}}$, Pb+Pb, 0-5%', density=True)\n",
    "plt.hist(diff_combine_4, bins=20, histtype='step', color=sns.color_palette(\"Set2\")[3], label='$R_{AA}^{h^{\\pm}}$, Pb+Pb, 30-40%', density=True)\n",
    "plt.axvline(x=0., color='k')\n",
    "plt.xlim(-0.5, 0.5)\n",
    "plt.legend()\n",
    "plt.xlabel('(emulator - model) / model')\n",
    "plt.tick_params(direction=\"in\", which='both')\n",
    "plt.savefig(path+'/plots/running_coupling/emulator_dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5eb164",
   "metadata": {},
   "outputs": [],
   "source": [
    "ParameterLabels = ['$\\\\beta_1$', '$\\\\beta_2$', '$T^*$', '$Q_0$', '$g^{inel}_{hard}$']\n",
    "ranges = np.array([[-0.8, 2], [-0.8, 2], [0.16, 0.6], [1.15, 3.5], [0.1, 0.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c58db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(model_parameters):\n",
    "    \"\"\"Evaluvate the prior at model prameter values. \n",
    "    If all parameters are inside bounds function will return 0 otherwise -inf\"\"\"\n",
    "    X = np.array(model_parameters).reshape(1,-1)\n",
    "    lower = np.all(X >= design_min)\n",
    "    upper = np.all(X <= design_max)\n",
    "    if (lower and upper):\n",
    "        lp=0\n",
    "    # lp = np.log(st.beta.pdf(X,5,1,dsgn_min_ut.reshape(1,-1),(dsgn_max_ut-dsgn_min_ut).reshape(1,-1))).sum()\n",
    "    else:\n",
    "        lp = -np.inf\n",
    "    return lp\n",
    "\n",
    "def mvn_loglike(y, cov):\n",
    "    \"\"\"\n",
    "    Evaluate the multivariate-normal log-likelihood for difference vector `y`\n",
    "    and covariance matrix `cov`:\n",
    "\n",
    "        log_p = -1/2*[(y^T).(C^-1).y + log(det(C))] + const.\n",
    "\n",
    "    The likelihood is NOT NORMALIZED, since this does not affect MCMC.  The\n",
    "    normalization const = -n/2*log(2*pi), where n is the dimensionality.\n",
    "\n",
    "    Arguments `y` and `cov` MUST be np.arrays with dtype == float64 and shapes\n",
    "    (n) and (n, n), respectively.  These requirements are NOT CHECKED.\n",
    "\n",
    "    The calculation follows algorithm 2.1 in Rasmussen and Williams (Gaussian\n",
    "    Processes for Machine Learning).\n",
    "\n",
    "    \"\"\"\n",
    "    # Compute the Cholesky decomposition of the covariance.\n",
    "    # Use bare LAPACK function to avoid scipy.linalg wrapper overhead.\n",
    "    L, info = lapack.dpotrf(cov, clean=False)\n",
    "\n",
    "    if info < 0:\n",
    "        raise ValueError(\n",
    "            'lapack dpotrf error: '\n",
    "            'the {}-th argument had an illegal value'.format(-info)\n",
    "        )\n",
    "    elif info < 0:\n",
    "        raise np.linalg.LinAlgError(\n",
    "            'lapack dpotrf error: '\n",
    "            'the leading minor of order {} is not positive definite'\n",
    "            .format(info)\n",
    "        )\n",
    "\n",
    "    # Solve for alpha = cov^-1.y using the Cholesky decomp.\n",
    "    alpha, info = lapack.dpotrs(L, y)\n",
    "\n",
    "    if info != 0:\n",
    "        raise ValueError(\n",
    "            'lapack dpotrs error: '\n",
    "            'the {}-th argument had an illegal value'.format(-info)\n",
    "         )\n",
    "\n",
    "    if np.all(L.diagonal()>0):\n",
    "        return -.5*np.dot(y, alpha) - np.log(L.diagonal()).sum()\n",
    "    else:\n",
    "        return -.5*np.dot(y, alpha) - np.log(np.abs(L.diagonal())).sum()\n",
    "        print(L.diagonal())\n",
    "        raise ValueError(\n",
    "            'L has negative values on diagonal {}'.format(L.diagonal())\n",
    "        )\n",
    "\n",
    "def log_posterior(model_parameters):\n",
    "    model_parameters = np.array([model_parameters[0], model_parameters[1], model_parameters[2], 1.75, model_parameters[3]])\n",
    "    mn, var = predict_observables(model_parameters)\n",
    "    delta_y = mn - y_exp\n",
    "    delta_y = delta_y.flatten()   \n",
    "    total_var = var + y_exp_variance\n",
    "    return log_prior(model_parameters) + mvn_loglike(delta_y,total_var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f691a7",
   "metadata": {},
   "source": [
    "# Closure Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f744017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate with true values\n",
    "# y_exp = np.loadtxt(path+'/data/true_RAA')\n",
    "# y_exp_err = np.loadtxt(path+'/data/true_RAA_err')\n",
    "# y_exp_variance = np.diag(y_exp_err**2)\n",
    "y_exp = np.loadtxt(path+'/data/running_coupling/data_val_4obs')\n",
    "y_exp_err = np.loadtxt(path+'/data/running_coupling/data_val_err_4obs')\n",
    "y_exp_variance = np.diag(y_exp_err**2)\n",
    "\n",
    "# print(y_err.shape)\n",
    "# y_exp = simulation[7]\n",
    "# y_err = np.loadtxt(path+'/data/RAA_data_err')\n",
    "# y_exp_variance = np.diag(y_err**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a4524c",
   "metadata": {},
   "source": [
    "## Reduce parameter dim to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90739bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_max = np.array([1., 1., 0.6, 0.4])\n",
    "test_min = np.array([-0.9, -0.9, 0.16, 0.1])\n",
    "test_ptp = test_max - test_min\n",
    "\n",
    "test_dim = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0bc6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwalkers = 20*test_dim  # number of MCMC walkers\n",
    "nburn = 1000 # \"burn-in\" period to let chains stabilize\n",
    "nsteps = 5000  # number of MCMC steps to take\n",
    "# filename = data_path(name+\".h5\")\n",
    "\n",
    "\n",
    "#backend = emcee.backends.HDFBackend(filename)\n",
    "starting_guesses = test_min + (test_max - test_min) * np.random.rand(nwalkers, test_dim)\n",
    "\n",
    "#print(starting_guesses)\n",
    "print(\"MCMC sampling using emcee (affine-invariant ensamble sampler) with {0} walkers\".format(nwalkers))\n",
    "with Pool() as pool:\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, test_dim, log_posterior)\n",
    "    print('burn in sampling started')    \n",
    "    pos = sampler.run_mcmc(starting_guesses, nburn, progress=True, store=True)\n",
    "    print(\"Mean acceptance fraction: {0:.3f} (in total {1} steps)\".format(\n",
    "                        np.mean(sampler.acceptance_fraction), nwalkers*nburn))\n",
    "    print('Burn in completed.')\n",
    "    print(\"Now running the samples\")\n",
    "    sampler.run_mcmc(initial_state=None, nsteps=nsteps, progress=True, tune=False)  \n",
    "    print(\"Mean acceptance fraction: {0:.3f} (in total {1} steps)\".format(\n",
    "                        np.mean(sampler.acceptance_fraction), nwalkers*nsteps))\n",
    "        \n",
    "    # discard burn-in points and flatten the walkers; the shape of samples is (nwalkers*nsteps, Xdim)\n",
    "    #samples = backend.get_chain(flat=True, discard=nburn)\n",
    "    samples = sampler.get_chain(flat=True, discard=nburn)\n",
    "\n",
    "# n_samples = len(samples)\n",
    "# samples = np.concatenate((np.array([samples.T[0]]), np.array([samples.T[0]]), np.array([samples.T[1:3]]), np.array([[2 for _ in range(n_samples)]]), np.array([samples.T[3]])), axis=-1)\n",
    "# print(samples.shape)\n",
    "\n",
    "np.savetxt(path+'/data/running_coupling/MCMC_test_samples', samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b668c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds=[(a,b) for (a,b) in zip(test_min,test_max)]\n",
    "parameters0 = optimize.differential_evolution(lambda x: -log_posterior(x), \n",
    "                                    bounds=bounds,\n",
    "                                    tol=1e-9,\n",
    "                                    ).x\n",
    "parameters1 = [np.percentile(it,50) for it in samples.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82457c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values = np.array([0., 0., 0.3, 0.25])\n",
    "# true_values = design[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ParameterLabels = ['$\\\\beta_\\perp$', '$\\\\beta_\\parallel$', '$T^*$',  '$\\\\alpha^{inel}_{s, hard}$']\n",
    "ranges = np.array([[-0.9, 1], [-0.9, 1], [0.16, 0.6], [0.1, 0.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec608f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = pd.DataFrame(samples, columns=ParameterLabels)\n",
    "g = sns.PairGrid(samples_df.iloc[:,:], corner=True, diag_sharey=False)\n",
    "g.map_lower(sns.histplot, bins=100, color=sns.color_palette()[9])\n",
    "g.map_diag(sns.kdeplot, linewidth=2, shade=True, color=sns.color_palette()[-1])\n",
    "for n in range(test_dim):\n",
    "    ax=g.axes[n][n]\n",
    "    ax.axvline(x=parameters0[n], ls='-', c=sns.color_palette()[9], label='MAP')\n",
    "    # ax.axvline(x=parameters1[n], ls='-', c=sns.color_palette()[0], label='central')\n",
    "    ax.axvline(x=true_values[n], ls='-', c=sns.color_palette()[3], label='Truth')\n",
    "    ax.text(0,0.9,s= f'{parameters0[n]:.2f}', transform=ax.transAxes, color=sns.color_palette()[9], fontsize=12)\n",
    "    # ax.text(0,0.8,s= f'{parameters1[n]:.2f}', transform=ax.transAxes, color=sns.color_palette()[0], fontsize=12)\n",
    "    ax.text(0,0.7,s= f'{true_values[n]:.2f}', transform=ax.transAxes, color=sns.color_palette()[3], fontsize=12)\n",
    "g.axes[2,2].legend(loc='upper right', fontsize=10)\n",
    "for i in range(test_dim):\n",
    "    for j in range(i+1):\n",
    "        g.axes[i,j].set_xlim(*ranges[j])\n",
    "        if i==j:\n",
    "            g.axes[i,j].set_ylim(*ranges[i])\n",
    "            \n",
    "        else:\n",
    "            g.axes[i,j].set_ylim(ymax=0)\n",
    "            g.axes[i,j].axvline(x=parameters0[j], ls='-', c=sns.color_palette()[9])\n",
    "            # g.axes[i,j].axvline(x=parameters1[j], ls='-', c=sns.color_palette()[0])\n",
    "            g.axes[i,j].axvline(x=true_values[j], ls='-', c=sns.color_palette()[3])\n",
    "            g.axes[i,j].axhline(y=parameters0[i], ls='-', c=sns.color_palette()[9])\n",
    "            # g.axes[i,j].axhline(y=parameters1[i], ls='-', c=sns.color_palette()[0])\n",
    "            g.axes[i,j].axhline(y=true_values[i], ls='-', c=sns.color_palette()[3])\n",
    "            g.axes[i,j].scatter(parameters0[j], parameters0[i], color=sns.color_palette()[9])\n",
    "            # g.axes[i,j].scatter(parameters1[j], parameters1[i], color=sns.color_palette()[0])\n",
    "            g.axes[i,j].scatter(true_values[j], true_values[i], color=sns.color_palette()[3])\n",
    "plt.tight_layout()\n",
    "plt.savefig(path+'/plots/running_coupling/Posterior_of_true_parameters_pca4_param4_obs4_dps32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3130fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsamples = 100\n",
    "Nthin = samples_df.size//Nsamples\n",
    "# prior parameter samples\n",
    "prior_params = (ranges[:,1]-ranges[:,0])*np.random.rand(Nsamples,test_dim) + ranges[:,0]\n",
    "# posterior parameter samples \n",
    "posterior_params =  samples_df.iloc[::Nthin,:].values\n",
    "prior_params = np.concatenate((np.array([prior_params.T[0]]).T, prior_params.T[1:3].T, np.array([[1.6 for _ in range(Nsamples)]]).T, np.array([prior_params.T[3]]).T), axis=1)\n",
    "posterior_params = np.concatenate((np.array([posterior_params.T[0]]).T, posterior_params.T[1:3].T, np.array([[1.6 for _ in range(len(posterior_params))]]).T, np.array([posterior_params.T[3]]).T), axis=1)\n",
    "\n",
    "prior_obs = []\n",
    "posterior_obs = []\n",
    "\n",
    "for p in prior_params: \n",
    "    A = np.array([predict_observables(p, diag_std=True)])\n",
    "    Y_predicted = A[:,0,:]\n",
    "    # prior_obs = np.array([np.concatenate(Y_predicted)])\n",
    "    prior_obs.append(list(Y_predicted[0]))\n",
    "\n",
    "for p in posterior_params: \n",
    "    A = np.array([predict_observables(p, diag_std=True)])\n",
    "    Y_predicted = A[:,0,:]\n",
    "    posterior_obs.append(list(Y_predicted[0]))\n",
    "    \n",
    "prior_obs = np.array(prior_obs)\n",
    "posterior_obs = np.array(posterior_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b18237",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,4, figsize=(16,8))\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "CLbins = [95]\n",
    "for isample, ilabel, color in zip([prior_obs, posterior_obs], \n",
    "                               ['prior','posterior'], \n",
    "                               [sns.color_palette()[0], sns.color_palette()[3]]):\n",
    "    for CL, opacity in zip(CLbins, [.35, .3, .25, .2]):\n",
    "        label = '{:d}% {}'.format(CL, ilabel)\n",
    "        lower, upper = np.percentile(isample, [50-CL/2., 50+CL/2.], axis=0)\n",
    "        axes[0, 0].fill_between(pT1, lower[:Nc1], upper[:Nc1], color=color, alpha=opacity, label=label)\n",
    "        axes[0, 1].fill_between(pT2, lower[Nc1:Nc2], upper[Nc1:Nc2], color=color, alpha=opacity, label=label)\n",
    "        axes[0, 2].fill_between(pT3, lower[Nc2:Nc3], upper[Nc2:Nc3], color=color, alpha=opacity, label=label)\n",
    "        axes[0, 3].fill_between(pT4, lower[Nc3:Nc4], upper[Nc3:Nc4], color=color, alpha=opacity, label=label)\n",
    "        axes[1, 0].fill_between(pT1, (lower/y_exp)[:Nc1], (upper/y_exp)[:Nc1], color=color, alpha=opacity, label=label)\n",
    "        axes[1, 1].fill_between(pT2, (lower/y_exp)[Nc1:Nc2], (upper/y_exp)[Nc1:Nc2], color=color, alpha=opacity, label=label)\n",
    "        axes[1, 2].fill_between(pT3, (lower/y_exp)[Nc2:Nc3], (upper/y_exp)[Nc2:Nc3], color=color, alpha=opacity, label=label)\n",
    "        axes[1, 3].fill_between(pT4, (lower/y_exp)[Nc3:Nc4], (upper/y_exp)[Nc3:Nc4], color=color, alpha=opacity, label=label)\n",
    "\n",
    "for i, ax,y,yerr,name, pT in zip(range(4), axes[0], \n",
    "                    [y_exp[:Nc1], y_exp[Nc1:Nc2], y_exp[Nc2:Nc3], y_exp[Nc3:Nc4]], [y_exp_err[:Nc1], y_exp_err[Nc1:Nc2], y_exp_err[Nc2:Nc3], y_exp_err[Nc3:Nc4]], \n",
    "                    [r\"$R_{\\rm AA}$\"]*4, [pT1, pT2, pT3, pT4]):\n",
    "\n",
    "    ax.errorbar(pT, y, yerr=yerr, fmt='k.', label='valid')\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(r\"$R_{\\rm AA}$\")\n",
    "    # ax.set_xlabel(\"pT (GeV)\")\n",
    "\n",
    "for i, ax,y,yerr,name, pT in zip(range(4), axes[1], \n",
    "                    [y_exp[:Nc1], y_exp[Nc1:Nc2], y_exp[Nc2:Nc3], y_exp[Nc3:Nc4]],[y_exp_err[:Nc1], y_exp_err[Nc1:Nc2], y_exp_err[Nc2:Nc3], y_exp_err[Nc3:Nc4]],\n",
    "                    [\"Ratio to data\"]*4, [pT1, pT2, pT3, pT4]):\n",
    "    ax.errorbar(pT, y/y, yerr=yerr/y, fmt='k.', label='valid')\n",
    "    ax.axhline(y=1, ls='-', color='k')\n",
    "    if i == 0: \n",
    "        ax.set_ylabel(\"Ratio to data\")\n",
    "    ax.set_xlabel(\"pT (GeV)\")\n",
    "# axes[0,0].semilogy()\n",
    "# axes[0,1].semilogy()\n",
    "axes[0, 0].set_ylim(0,1.8)\n",
    "axes[0, 1].set_ylim(0,1.8)\n",
    "axes[0, 2].set_ylim(0,1.8)\n",
    "axes[0, 3].set_ylim(0,1.8)\n",
    "axes[1, 0].set_ylim(0,2)\n",
    "axes[1, 1].set_ylim(0,2)\n",
    "axes[1, 2].set_ylim(0,2)\n",
    "axes[1, 3].set_ylim(0,2)\n",
    "axes[0, 0].set_title('Au+Au 200 GeV, 0-10%', fontsize=16)\n",
    "axes[0, 1].set_title('Pb+Pb 2760 GeV, 0-5%', fontsize=16)\n",
    "axes[0, 2].set_title('Au+Au 200 GeV, 20-30%', fontsize=16)\n",
    "axes[0, 3].set_title('Pb+Pb 2760 GeV, 30-40%', fontsize=16)\n",
    "axes[0, 0].legend(prop={'size': 12})\n",
    "axes[0, 1].legend(prop={'size': 12})\n",
    "axes[0, 2].legend(prop={'size': 12})\n",
    "axes[0, 3].legend(prop={'size': 12})\n",
    "axes[0, 1].tick_params(axis='y', which='both', labelleft=False)\n",
    "axes[0, 2].tick_params(axis='y', which='both', labelleft=False)\n",
    "axes[0, 3].tick_params(axis='y', which='both', labelleft=False)\n",
    "axes[1, 1].tick_params(axis='y', which='both', labelleft=False)\n",
    "axes[1, 2].tick_params(axis='y', which='both', labelleft=False)\n",
    "axes[1, 3].tick_params(axis='y', which='both', labelleft=False)\n",
    "axes[0, 0].tick_params(direction=\"in\", which='both')\n",
    "axes[0, 1].tick_params(direction=\"in\", which='both')\n",
    "axes[0, 2].tick_params(direction=\"in\", which='both')\n",
    "axes[0, 3].tick_params(direction=\"in\", which='both')\n",
    "axes[1, 0].tick_params(direction=\"in\", which='both')\n",
    "axes[1, 1].tick_params(direction=\"in\", which='both')\n",
    "axes[1, 2].tick_params(direction=\"in\", which='both')\n",
    "axes[1, 3].tick_params(direction=\"in\", which='both')\n",
    "\n",
    "# plt.legend(loc='upper center', bbox_to_anchor=(0, -0.1), fancybox=True, shadow=True, ncol=3)\n",
    "# plt.tight_layout()\n",
    "plt.savefig(path+\"/plots/running_coupling/Posterior_validation_pca2_param4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3431961e",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac99ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(model_parameters):\n",
    "    \"\"\"Evaluvate the prior at model prameter values. \n",
    "    If all parameters are inside bounds function will return 0 otherwise -inf\"\"\"\n",
    "    X = np.array(model_parameters).reshape(1,-1)\n",
    "    lower = np.all(X >= design_min)\n",
    "    upper = np.all(X <= design_max)\n",
    "    if (lower and upper):\n",
    "        lp=0\n",
    "    # lp = np.log(st.beta.pdf(X,5,1,dsgn_min_ut.reshape(1,-1),(dsgn_max_ut-dsgn_min_ut).reshape(1,-1))).sum()\n",
    "    else:\n",
    "        lp = -np.inf\n",
    "    return lp\n",
    "\n",
    "def mvn_loglike(y, cov):\n",
    "    \"\"\"\n",
    "    Evaluate the multivariate-normal log-likelihood for difference vector `y`\n",
    "    and covariance matrix `cov`:\n",
    "\n",
    "        log_p = -1/2*[(y^T).(C^-1).y + log(det(C))] + const.\n",
    "\n",
    "    The likelihood is NOT NORMALIZED, since this does not affect MCMC.  The\n",
    "    normalization const = -n/2*log(2*pi), where n is the dimensionality.\n",
    "\n",
    "    Arguments `y` and `cov` MUST be np.arrays with dtype == float64 and shapes\n",
    "    (n) and (n, n), respectively.  These requirements are NOT CHECKED.\n",
    "\n",
    "    The calculation follows algorithm 2.1 in Rasmussen and Williams (Gaussian\n",
    "    Processes for Machine Learning).\n",
    "\n",
    "    \"\"\"\n",
    "    # Compute the Cholesky decomposition of the covariance.\n",
    "    # Use bare LAPACK function to avoid scipy.linalg wrapper overhead.\n",
    "    L, info = lapack.dpotrf(cov, clean=False)\n",
    "\n",
    "    if info < 0:\n",
    "        raise ValueError(\n",
    "            'lapack dpotrf error: '\n",
    "            'the {}-th argument had an illegal value'.format(-info)\n",
    "        )\n",
    "    elif info < 0:\n",
    "        raise np.linalg.LinAlgError(\n",
    "            'lapack dpotrf error: '\n",
    "            'the leading minor of order {} is not positive definite'\n",
    "            .format(info)\n",
    "        )\n",
    "\n",
    "    # Solve for alpha = cov^-1.y using the Cholesky decomp.\n",
    "    alpha, info = lapack.dpotrs(L, y)\n",
    "\n",
    "    if info != 0:\n",
    "        raise ValueError(\n",
    "            'lapack dpotrs error: '\n",
    "            'the {}-th argument had an illegal value'.format(-info)\n",
    "         )\n",
    "\n",
    "    if np.all(L.diagonal()>0):\n",
    "        return -.5*np.dot(y, alpha) - np.log(L.diagonal()).sum()\n",
    "    else:\n",
    "        return -.5*np.dot(y, alpha) - np.log(np.abs(L.diagonal())).sum()\n",
    "        print(L.diagonal())\n",
    "        raise ValueError(\n",
    "            'L has negative values on diagonal {}'.format(L.diagonal())\n",
    "        )\n",
    "\n",
    "def log_posterior(model_parameters):\n",
    "    \"\"\"\n",
    "    model_parameters = np.array([model_parameters[0], model_parameters[1], model_parameters[2], 2.1, model_parameters[3]])\n",
    "    mn1, var1 = predict_observables(model_parameters)\n",
    "    model_parameter_2 = model_parameters\n",
    "    model_parameter_2[3] *= 1.151589045\n",
    "    mn2, var2 = predict_observables(model_parameter_2)\n",
    "    model_parameter_3 = model_parameters\n",
    "    model_parameter_3[3] *= 0.7194298318\n",
    "    mn3, var3 = predict_observables(model_parameter_3)\n",
    "    model_parameter_4 = model_parameters\n",
    "    model_parameter_4[3] *= 0.8473325979\n",
    "    mn4, var4 = predict_observables(model_parameter_4)\n",
    "    \n",
    "    mn = np.concatenate((mn1[:Nc1], mn2[Nc1:Nc2], mn3[Nc2:Nc3], mn4[Nc3:]))\n",
    "    var = np.concatenate((var1[:Nc1], var2[Nc1:Nc2], var3[Nc2:Nc3], var4[Nc3:]))\n",
    "    \"\"\"\n",
    "    # model_parameters = np.array([model_parameters[0], model_parameters[1], model_parameters[2], 1.8, model_parameters[3]])\n",
    "    mn, var = predict_observables(model_parameters)\n",
    "    delta_y = mn - y_exp\n",
    "    delta_y = delta_y.flatten()   \n",
    "    total_var = var + y_exp_variance\n",
    "    return log_prior(model_parameters) + mvn_loglike(delta_y,total_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2dce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_exp = np.loadtxt(path+'/data/running_coupling/data_exp_4obs')\n",
    "y_exp_err = np.loadtxt(path+'/data/running_coupling/data_exp_err_4obs')\n",
    "y_exp_variance = np.diag(y_exp_err**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d2415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_max = np.array([2., 2., 0.6, 2.5, 0.4])\n",
    "test_min = np.array([-0.9, -0.9, 0.16, 1.45, 0.1])\n",
    "test_ptp = test_max - test_min\n",
    "\n",
    "test_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3be276",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwalkers = 20*test_dim  # number of MCMC walkers\n",
    "nburn = 1000 # \"burn-in\" period to let chains stabilize\n",
    "nsteps = 5000  # number of MCMC steps to take\n",
    "# filename = data_path(name+\".h5\")\n",
    "\n",
    "\n",
    "#backend = emcee.backends.HDFBackend(filename)\n",
    "starting_guesses = test_min + (test_max - test_min) * np.random.rand(nwalkers, test_dim)\n",
    "#print(starting_guesses)\n",
    "print(\"MCMC sampling using emcee (affine-invariant ensamble sampler) with {0} walkers\".format(nwalkers))\n",
    "with Pool() as pool:\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, test_dim, log_posterior)\n",
    "    print('burn in sampling started')    \n",
    "    pos = sampler.run_mcmc(starting_guesses, nburn, progress=True, store=True)\n",
    "    print(\"Mean acceptance fraction: {0:.3f} (in total {1} steps)\".format(\n",
    "                        np.mean(sampler.acceptance_fraction), nwalkers*nburn))\n",
    "    print('Burn in completed.')\n",
    "    print(\"Now running the samples\")\n",
    "    sampler.run_mcmc(initial_state=None, nsteps=nsteps, progress=True, tune=False)  \n",
    "    print(\"Mean acceptance fraction: {0:.3f} (in total {1} steps)\".format(\n",
    "                        np.mean(sampler.acceptance_fraction), nwalkers*nsteps))\n",
    "        \n",
    "    # discard burn-in points and flatten the walkers; the shape of samples is (nwalkers*nsteps, Xdim)\n",
    "    #samples = backend.get_chain(flat=True, discard=nburn)\n",
    "    samples = sampler.get_chain(flat=True, discard=nburn)\n",
    "\n",
    "np.savetxt(path+'/data/running_coupling/MCMC_samples', samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d5629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds=[(a,b) for (a,b) in zip(test_min,test_max)]\n",
    "parameters0 = optimize.differential_evolution(lambda x: -log_posterior(x), \n",
    "                                    bounds=bounds,\n",
    "                                    tol=1e-9,\n",
    "                                    ).x\n",
    "parameters1 = [np.percentile(it,50) for it in samples.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca2dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19a4e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ParameterLabels = ['$\\\\beta_\\perp$', '$\\\\beta_\\parallel$', '$T^*$',  '$Q_0$', '$\\\\alpha^{inel}_{s, hard}$']\n",
    "ranges = np.array([[-0.9, 2], [-0.9, 2], [0.16, 0.6], [1.45, 2.5], [0.1, 0.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169524d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = pd.DataFrame(samples, columns=ParameterLabels)\n",
    "plt.rcParams[\"axes.labelsize\"] = 16\n",
    "g = sns.PairGrid(samples_df.iloc[:,:], corner=True, diag_sharey=False)\n",
    "g.map_lower(sns.histplot, bins=100, color=sns.color_palette()[0])\n",
    "g.map_diag(sns.kdeplot, linewidth=2, shade=True, color=sns.color_palette()[0])\n",
    "for n in range(test_dim):\n",
    "    ax=g.axes[n][n]\n",
    "    ax.axvline(x=parameters0[n], ls='-', c=sns.color_palette()[0], label='MAP')\n",
    "    # ax.axvline(x=parameters1[n], ls='-', c=sns.color_palette()[9], label='central')\n",
    "    # ax.axvline(x=true_values[n], ls='-', c=sns.color_palette()[3], label='Truth')\n",
    "    ax.text(0.1,0.7,s= f'{parameters0[n]:.2f}', transform=ax.transAxes, color=sns.color_palette()[0], fontsize=16)\n",
    "    # ax.text(0.1,0.8,s= f'{parameters1[n]:.2f}', transform=ax.transAxes, color=sns.color_palette()[9], fontsize=16)\n",
    "    # ax.text(0,0.8,s= f'{true_values[n]:.2f}', transform=ax.transAxes, color=sns.color_palette()[3], fontsize=12)\n",
    "g.axes[1,1].legend(loc='best', fontsize=11)\n",
    "for i in range(test_dim):\n",
    "    for j in range(i+1):\n",
    "        g.axes[i,j].set_xlim(*ranges[j])\n",
    "        if i==j:\n",
    "            g.axes[i,j].set_ylim(*ranges[i])\n",
    "            \n",
    "        else:\n",
    "            # g.axes[i,j].set_ylim(0, 2)\n",
    "            g.axes[i,j].axvline(x=parameters0[j], ls='-', c=sns.color_palette()[0])\n",
    "            # g.axes[i,j].axvline(x=parameters1[j], ls='-', c=sns.color_palette()[9])\n",
    "            # g.axes[i,j].axvline(x=true_values[j], ls='-', c=sns.color_palette()[3])\n",
    "            g.axes[i,j].axhline(y=parameters0[i], ls='-', c=sns.color_palette()[0])\n",
    "            # g.axes[i,j].axhline(y=parameters1[i], ls='-', c=sns.color_palette()[9])\n",
    "            # g.axes[i,j].axhline(y=true_values[i], ls='-', c=sns.color_palette()[3])\n",
    "            g.axes[i,j].scatter(parameters0[j], parameters0[i], color='red')\n",
    "            # g.axes[i,j].scatter(parameters1[j], parameters1[i], color=sns.color_palette()[9])\n",
    "            # g.axes[i,j].scatter(true_values[j], true_values[i], color=sns.color_palette()[3])\n",
    "plt.tight_layout()\n",
    "plt.savefig(path+'/plots/running_coupling/Posterior_of_parameters_obs4_param5_pc2_dps60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0847724",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsamples = 100\n",
    "Nthin = samples_df.size//Nsamples\n",
    "# prior parameter samples\n",
    "prior_params = (ranges[:,1]-ranges[:,0])*np.random.rand(Nsamples,test_dim) + ranges[:,0]\n",
    "# posterior parameter samples \n",
    "posterior_params =  samples_df.iloc[::Nthin,:].values\n",
    "# prior_params = np.concatenate((np.array([prior_params.T[0]]).T, prior_params.T[1:3].T, np.array([[1.8 for _ in range(Nsamples)]]).T, np.array([prior_params.T[3]]).T), axis=1)\n",
    "# posterior_params = np.concatenate((np.array([posterior_params.T[0]]).T, posterior_params.T[1:3].T, np.array([[1.8 for _ in range(len(posterior_params))]]).T, np.array([posterior_params.T[3]]).T), axis=1)\n",
    "prior_obs = []\n",
    "posterior_obs = []\n",
    "\n",
    "for p in prior_params: \n",
    "    A = np.array([predict_observables(p, diag_std=True)])\n",
    "    Y_predicted = A[:,0,:]\n",
    "    \"\"\"\n",
    "    p2 = p\n",
    "    p2[3] *= 1.151589045\n",
    "    A2 = np.array([predict_observables(p2, diag_std=True)])\n",
    "    Y_predicted2 = A2[:,0,:]\n",
    "    p3 = p\n",
    "    p3[3] *= 0.7194298318\n",
    "    A3 = np.array([predict_observables(p3, diag_std=True)])\n",
    "    Y_predicted3 = A3[:,0,:]\n",
    "    p4 = p\n",
    "    p4[3] *= 0.8473325979\n",
    "    A4 = np.array([predict_observables(p4, diag_std=True)])\n",
    "    Y_predicted4 = A4[:,0,:]\n",
    "    Y_predicted_ = np.concatenate((Y_predicted[0][:Nc1], Y_predicted2[0][Nc1:Nc2], Y_predicted3[0][Nc2:Nc3], Y_predicted4[0][Nc3:]))\n",
    "    \"\"\"\n",
    "    prior_obs.append(list(Y_predicted[0]))\n",
    "\n",
    "for p in posterior_params: \n",
    "    A = np.array([predict_observables(p, diag_std=True)])\n",
    "    Y_predicted = A[:,0,:]\n",
    "    \"\"\"\n",
    "    p2 = p\n",
    "    p2[3] *= 1.151589045\n",
    "    A2 = np.array([predict_observables(p2, diag_std=True)])\n",
    "    Y_predicted2 = A2[:,0,:]\n",
    "    p3 = p\n",
    "    p3[3] *= 0.7194298318\n",
    "    A3 = np.array([predict_observables(p3, diag_std=True)])\n",
    "    Y_predicted3 = A3[:,0,:]\n",
    "    p4 = p\n",
    "    p4[3] *= 0.8473325979\n",
    "    A4 = np.array([predict_observables(p4, diag_std=True)])\n",
    "    Y_predicted4 = A4[:,0,:]\n",
    "    Y_predicted_ = np.concatenate((Y_predicted[0][:Nc1], Y_predicted2[0][Nc1:Nc2], Y_predicted3[0][Nc2:Nc3], Y_predicted4[0][Nc3:]))\n",
    "    \"\"\"\n",
    "    posterior_obs.append(list(Y_predicted[0]))\n",
    "    \n",
    "prior_obs = np.array(prior_obs)\n",
    "posterior_obs = np.array(posterior_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8165678",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,4, figsize=(16,8))\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "CLbins = [95]\n",
    "for isample, ilabel, color in zip([prior_obs, posterior_obs], \n",
    "                               ['prior','posterior'], \n",
    "                               [sns.color_palette()[0], sns.color_palette()[3]]):\n",
    "    for CL, opacity in zip(CLbins, [.35, .3, .25, .2]):\n",
    "        label = '{:d}% {}'.format(CL, ilabel)\n",
    "        lower, upper = np.percentile(isample, [50-CL/2., 50+CL/2.], axis=0)\n",
    "        axes[0, 0].fill_between(pT1, lower[:Nc1], upper[:Nc1], color=color, alpha=opacity, label=label)\n",
    "        axes[0, 1].fill_between(pT2, lower[Nc1:Nc2], upper[Nc1:Nc2], color=color, alpha=opacity, label=label)\n",
    "        axes[0, 2].fill_between(pT3, lower[Nc2:Nc3], upper[Nc2:Nc3], color=color, alpha=opacity, label=label)\n",
    "        axes[0, 3].fill_between(pT4, lower[Nc3:Nc4], upper[Nc3:Nc4], color=color, alpha=opacity, label=label)\n",
    "        axes[1, 0].fill_between(pT1, (lower/y_exp)[:Nc1], (upper/y_exp)[:Nc1], color=color, alpha=opacity, label=label)\n",
    "        axes[1, 1].fill_between(pT2, (lower/y_exp)[Nc1:Nc2], (upper/y_exp)[Nc1:Nc2], color=color, alpha=opacity, label=label)\n",
    "        axes[1, 2].fill_between(pT3, (lower/y_exp)[Nc2:Nc3], (upper/y_exp)[Nc2:Nc3], color=color, alpha=opacity, label=label)\n",
    "        axes[1, 3].fill_between(pT4, (lower/y_exp)[Nc3:Nc4], (upper/y_exp)[Nc3:Nc4], color=color, alpha=opacity, label=label)\n",
    "\n",
    "for i, ax,y,yerr,name, pT in zip(range(4), axes[0], \n",
    "                    [y_exp[:Nc1], y_exp[Nc1:Nc2], y_exp[Nc2:Nc3], y_exp[Nc3:Nc4]], [y_exp_err[:Nc1], y_exp_err[Nc1:Nc2], y_exp_err[Nc2:Nc3], y_exp_err[Nc3:Nc4]], \n",
    "                    [r\"$R_{\\rm AA}$\"]*4, [pT1, pT2, pT3, pT4]):\n",
    "\n",
    "    ax.errorbar(pT, y, yerr=yerr, fmt='k.', label='valid')\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(r\"$R_{\\rm AA}$\")\n",
    "    # ax.set_xlabel(\"pT (GeV)\")\n",
    "\n",
    "for i, ax,y,yerr,name, pT in zip(range(4), axes[1], \n",
    "                    [y_exp[:Nc1], y_exp[Nc1:Nc2], y_exp[Nc2:Nc3], y_exp[Nc3:Nc4]],[y_exp_err[:Nc1], y_exp_err[Nc1:Nc2], y_exp_err[Nc2:Nc3], y_exp_err[Nc3:Nc4]],\n",
    "                    [\"Ratio to data\"]*4, [pT1, pT2, pT3, pT4]):\n",
    "    ax.errorbar(pT, y/y, yerr=yerr/y, fmt='k.', label='valid')\n",
    "    ax.axhline(y=1, ls='-', color='k')\n",
    "    if i == 0: \n",
    "        ax.set_ylabel(\"Ratio to data\")\n",
    "    ax.set_xlabel(\"pT (GeV)\")\n",
    "# axes[0,0].semilogy()\n",
    "# axes[0,1].semilogy()\n",
    "axes[0, 0].set_ylim(0,1.8)\n",
    "axes[0, 1].set_ylim(0,1.8)\n",
    "axes[0, 2].set_ylim(0,1.8)\n",
    "axes[0, 3].set_ylim(0,1.8)\n",
    "axes[1, 0].set_ylim(0,2)\n",
    "axes[1, 1].set_ylim(0,2)\n",
    "axes[1, 2].set_ylim(0,2)\n",
    "axes[1, 3].set_ylim(0,2)\n",
    "axes[0, 0].set_title('Au+Au 200 GeV, 0-10%', fontsize=16)\n",
    "axes[0, 1].set_title('Pb+Pb 2760 GeV, 0-5%', fontsize=16)\n",
    "axes[0, 2].set_title('Au+Au 200 GeV, 20-30%', fontsize=16)\n",
    "axes[0, 3].set_title('Pb+Pb 2760 GeV, 30-40%', fontsize=16)\n",
    "axes[0, 0].legend(prop={'size': 12})\n",
    "axes[0, 1].legend(prop={'size': 12})\n",
    "axes[0, 2].legend(prop={'size': 12})\n",
    "axes[0, 3].legend(prop={'size': 12})\n",
    "axes[0, 1].tick_params(axis='y', which='both', labelleft=False)\n",
    "axes[0, 2].tick_params(axis='y', which='both', labelleft=False)\n",
    "axes[0, 3].tick_params(axis='y', which='both', labelleft=False)\n",
    "axes[1, 1].tick_params(axis='y', which='both', labelleft=False)\n",
    "axes[1, 2].tick_params(axis='y', which='both', labelleft=False)\n",
    "axes[1, 3].tick_params(axis='y', which='both', labelleft=False)\n",
    "axes[0, 0].tick_params(direction=\"in\", which='both')\n",
    "axes[0, 1].tick_params(direction=\"in\", which='both')\n",
    "axes[0, 2].tick_params(direction=\"in\", which='both')\n",
    "axes[0, 3].tick_params(direction=\"in\", which='both')\n",
    "axes[1, 0].tick_params(direction=\"in\", which='both')\n",
    "axes[1, 1].tick_params(direction=\"in\", which='both')\n",
    "axes[1, 2].tick_params(direction=\"in\", which='both')\n",
    "axes[1, 3].tick_params(direction=\"in\", which='both')\n",
    "\n",
    "# plt.legend(loc='upper center', bbox_to_anchor=(0, -0.1), fancybox=True, shadow=True, ncol=3)\n",
    "# plt.tight_layout()\n",
    "plt.savefig(path+\"/plots/running_coupling/Posterior_pca2_lower1-5_param5_dps60_pc2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7712b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = 0.1189\n",
    "Q = 91.1876\n",
    "Lambda = 0.2\n",
    "NC = 3\n",
    "Nf = 3\n",
    "CA = 3\n",
    "c0 = cc / (4*np.pi/9/(np.log((Q/Lambda)**2)))\n",
    "g_const = np.sqrt(4*np.pi*0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e08adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CL = 95\n",
    "plt.figure()\n",
    "T_list = np.arange(0.16, 0.6, 0.001)\n",
    "prior_qpara = [[] for _ in range(len(prior_params))]\n",
    "for i, prior in enumerate(prior_params): \n",
    "    beta_perp, beta_para, Tstar, Q0, alpha = prior\n",
    "    qpara = []\n",
    "    for iT in T_list: \n",
    "        c = 4*np.pi/9/(np.log((2*np.pi*max(iT, Tstar)/Lambda)**2)) * c0\n",
    "        g = np.sqrt(4.*np.pi*c)\n",
    "        mD_2 = g**2*iT**2*(NC/3+Nf/6)\n",
    "        Minf_2 = mD_2/2\n",
    "        mu = 4*iT\n",
    "        qhat_QCD = g**2*CA*iT*Minf_2/4/np.pi*np.log(1+(mu/Minf_2)**2)\n",
    "        qpara.append(qhat_QCD*(1+beta_para*(Lambda/iT))/(iT**3))\n",
    "    prior_qpara[i] = qpara\n",
    "lower, upper = np.percentile(prior_qpara, [50-CL/2., 50+CL/2.], axis=0)\n",
    "plt.fill_between(T_list, lower, upper, color=sns.color_palette()[0], alpha=0.35, label='95% prior')\n",
    "\n",
    "posterior_qpara = [[] for _ in range(len(posterior_params))]\n",
    "for i, posterior in enumerate(posterior_params): \n",
    "    beta_perp, beta_para, Tstar, Q0, alpha = posterior\n",
    "    qpara = []\n",
    "    qhat_const = []\n",
    "    for iT in T_list: \n",
    "        c = 4*np.pi/9/(np.log((2*np.pi*max(iT, Tstar)/Lambda)**2)) * c0\n",
    "        g = np.sqrt(4.*np.pi*c)\n",
    "        mD_2 = g**2*iT**2*(NC/3+Nf/6)\n",
    "        Minf_2 = mD_2/2\n",
    "        mu = 4*iT\n",
    "        qhat_QCD = g**2*CA*iT*Minf_2/4/np.pi*np.log(1+(mu/Minf_2)**2)\n",
    "        qpara.append(qhat_QCD*(1+beta_para*(Lambda/iT))/(iT**3))\n",
    "        qhat_const.append(g_const**2*CA*iT*Minf_2/4/np.pi*np.log(1+(mu/Minf_2)**2)/iT**3)\n",
    "    posterior_qpara[i] = qpara\n",
    "lower, upper = np.percentile(posterior_qpara, [50-CL/2., 50+CL/2.], axis=0)\n",
    "central = np.percentile(posterior_qpara, 50, axis=0)\n",
    "plt.fill_between(T_list, lower, upper, color=sns.color_palette()[3], alpha=0.35, label='95% posterior')\n",
    "plt.plot(T_list, np.mean(np.array(posterior_qpara), axis=0), label='mean', color=sns.color_palette()[3])\n",
    "plt.plot(T_list, qhat_const, '--', label='pQCD', color='black')\n",
    "plt.tick_params(direction=\"in\", which='both')\n",
    "plt.xlabel('T (GeV)')\n",
    "plt.ylabel('$\\hat{q}_L / T^3$')\n",
    "plt.legend()\n",
    "plt.xlim(0.16, 0.6)\n",
    "plt.ylim(0, 50)\n",
    "plt.savefig(path+\"/plots/running_coupling/qhat_dependence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5775215b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
